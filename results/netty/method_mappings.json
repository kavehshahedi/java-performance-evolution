{
    "9993e07356ea39edf14008789d3377d2bb62ea92": [
        {
            "commit_message": "Revert \"Speed-up HTTP 1.1 header and line parsing (#12321)\"\n\nMotivation:\n\nThis commit introduced a regression while parsing headers that could lead to IndexOutOfBoundsException.\n\nModifications\n\nReverts commit 0daaec3ac2715bf09dd385a0515b0031d5af486a.\n\nResult:\n\nFixes https://github.com/netty/netty/issues/13213\n",
            "benchmark": "io.netty.microbench.http.HttpFragmentedRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "public static io.netty.handler.codec.http.HttpVersion io.netty.handler.codec.http.HttpVersion.valueOf(java.lang.String)",
            "method_name_cc": "public static HttpVersion io.netty.handler.codec.http.HttpVersion.valueOf(String text)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpVersion.java",
            "previous_method_cc": "public static HttpVersion io.netty.handler.codec.http.HttpVersion.valueOf(String text)",
            "previous_method_pd": "public static io.netty.handler.codec.http.HttpVersion io.netty.handler.codec.http.HttpVersion.valueOf(java.lang.String)",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpVersion.java",
            "previous_commit": "4475b5c5719e7e7f36f2f01e25c139bcb2b048d4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 3.3333333333333335,
                "p_value": 0.0,
                "effect_size": -0.058372523404904966,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 833388,
                    "after": 776290
                }
            }
        },
        {
            "commit_message": "Revert \"Speed-up HTTP 1.1 header and line parsing (#12321)\"\n\nMotivation:\n\nThis commit introduced a regression while parsing headers that could lead to IndexOutOfBoundsException.\n\nModifications\n\nReverts commit 0daaec3ac2715bf09dd385a0515b0031d5af486a.\n\nResult:\n\nFixes https://github.com/netty/netty/issues/13213\n",
            "benchmark": "io.netty.microbench.http.HttpFragmentedRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "public static io.netty.handler.codec.http.HttpMethod io.netty.handler.codec.http.HttpMethod.valueOf(java.lang.String)",
            "method_name_cc": "public static HttpMethod io.netty.handler.codec.http.HttpMethod.valueOf(String name)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpMethod.java",
            "previous_method_cc": "public static HttpMethod io.netty.handler.codec.http.HttpMethod.valueOf(String name)",
            "previous_method_pd": "public static io.netty.handler.codec.http.HttpMethod io.netty.handler.codec.http.HttpMethod.valueOf(java.lang.String)",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpMethod.java",
            "previous_commit": "4475b5c5719e7e7f36f2f01e25c139bcb2b048d4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "regression",
                "median_change_percentage": 9.777015437392796,
                "p_value": 0.0,
                "effect_size": -0.2086111194318145,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 846327,
                    "after": 798527
                }
            }
        },
        {
            "commit_message": "Revert \"Speed-up HTTP 1.1 header and line parsing (#12321)\"\n\nMotivation:\n\nThis commit introduced a regression while parsing headers that could lead to IndexOutOfBoundsException.\n\nModifications\n\nReverts commit 0daaec3ac2715bf09dd385a0515b0031d5af486a.\n\nResult:\n\nFixes https://github.com/netty/netty/issues/13213\n",
            "benchmark": "io.netty.microbench.http.HttpFragmentedRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "private io.netty.handler.codec.http.HttpObjectDecoder$State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(io.netty.buffer.ByteBuf)",
            "method_name_cc": "private State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(ByteBuf buffer)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_method_cc": "private State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(ByteBuf buffer)",
            "previous_method_pd": "private io.netty.handler.codec.http.HttpObjectDecoder$State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(io.netty.buffer.ByteBuf)",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_commit": "4475b5c5719e7e7f36f2f01e25c139bcb2b048d4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 5.0761421319796955,
                "p_value": 0.0,
                "effect_size": -0.13345183546555275,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 7943609,
                    "after": 7705613
                }
            }
        },
        {
            "commit_message": "Revert \"Speed-up HTTP 1.1 header and line parsing (#12321)\"\n\nMotivation:\n\nThis commit introduced a regression while parsing headers that could lead to IndexOutOfBoundsException.\n\nModifications\n\nReverts commit 0daaec3ac2715bf09dd385a0515b0031d5af486a.\n\nResult:\n\nFixes https://github.com/netty/netty/issues/13213\n",
            "benchmark": "io.netty.microbench.http.HttpFragmentedRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List) throws java.lang.Exception",
            "method_name_cc": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(ChannelHandlerContext ctx, ByteBuf buffer, List<Object> out)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_method_cc": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(ChannelHandlerContext ctx, ByteBuf buffer, List<Object> out)",
            "previous_method_pd": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List) throws java.lang.Exception",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_commit": "4475b5c5719e7e7f36f2f01e25c139bcb2b048d4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 2.0689655172413794,
                "p_value": 0.0,
                "effect_size": -0.024511300845727526,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 8855468,
                    "after": 8240016
                }
            }
        }
    ],
    "33247074a0becce08c1f48eec61e8da0c7bbe4c0": [
        {
            "commit_message": "Make \"pinned memory\" from PooledByteBufAllocator reflect buffers in use (#11990)\n\nMotivation:\r\nThe pinned memory accounting was being done from a bad place.\r\nNamely, it was being done at the same time as the PoolChunk free memory accounting was being done.\r\nThat means the thread local caching was messing up the accuracy of the numbers.\r\n\r\nModification:\r\nMove pinned memory accounting to the PooledByteBuf init and deallocation methods, so it's tied to the buffer life cycle.\r\n\r\nResult:\r\nThe pinned memory accounting is updated as part of the pooled buffer life cycle, and is no longer being tricked by the activities of the thread-local buffer cache.\r\n\r\nFixes #11984",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "private long io.netty.buffer.PoolChunk.allocateRun(int)",
            "method_name_cc": "private long io.netty.buffer.PoolChunk<T>.allocateRun(int runSize)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "private long io.netty.buffer.PoolChunk<T>.allocateRun(int runSize)",
            "previous_method_pd": "private long io.netty.buffer.PoolChunk.allocateRun(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "d60ea595bcd2399530d8becbced45df0b9b22aa5",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -8.964131655143886,
                "p_value": 0.6852447878580459,
                "effect_size": 0.05226480836236934,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 42,
                    "after": 41
                }
            }
        },
        {
            "commit_message": "Make \"pinned memory\" from PooledByteBufAllocator reflect buffers in use (#11990)\n\nMotivation:\r\nThe pinned memory accounting was being done from a bad place.\r\nNamely, it was being done at the same time as the PoolChunk free memory accounting was being done.\r\nThat means the thread local caching was messing up the accuracy of the numbers.\r\n\r\nModification:\r\nMove pinned memory accounting to the PooledByteBuf init and deallocation methods, so it's tied to the buffer life cycle.\r\n\r\nResult:\r\nThe pinned memory accounting is updated as part of the pooled buffer life cycle, and is no longer being tricked by the activities of the thread-local buffer cache.\r\n\r\nFixes #11984",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "private void io.netty.buffer.PooledByteBuf.init0(io.netty.buffer.PoolChunk,java.nio.ByteBuffer,long,int,int,int,io.netty.buffer.PoolThreadCache)",
            "method_name_cc": "private void io.netty.buffer.PooledByteBuf<T>.init0(PoolChunk<T> chunk, ByteBuffer nioBuffer, long handle, int offset, int length, int maxLength, PoolThreadCache cache)",
            "file": "buffer/src/main/java/io/netty/buffer/PooledByteBuf.java",
            "previous_method_cc": "private void io.netty.buffer.PooledByteBuf<T>.init0(PoolChunk<T> chunk, ByteBuffer nioBuffer, long handle, int offset, int length, int maxLength, PoolThreadCache cache)",
            "previous_method_pd": "private void io.netty.buffer.PooledByteBuf.init0(io.netty.buffer.PoolChunk,java.nio.ByteBuffer,long,int,int,int,io.netty.buffer.PoolThreadCache)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PooledByteBuf.java",
            "previous_commit": "d60ea595bcd2399530d8becbced45df0b9b22aa5",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -5.714285714285714,
                "p_value": 0.0,
                "effect_size": -0.03522045646878662,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 4921934,
                    "after": 4780671
                }
            }
        },
        {
            "commit_message": "Make \"pinned memory\" from PooledByteBufAllocator reflect buffers in use (#11990)\n\nMotivation:\r\nThe pinned memory accounting was being done from a bad place.\r\nNamely, it was being done at the same time as the PoolChunk free memory accounting was being done.\r\nThat means the thread local caching was messing up the accuracy of the numbers.\r\n\r\nModification:\r\nMove pinned memory accounting to the PooledByteBuf init and deallocation methods, so it's tied to the buffer life cycle.\r\n\r\nResult:\r\nThe pinned memory accounting is updated as part of the pooled buffer life cycle, and is no longer being tricked by the activities of the thread-local buffer cache.\r\n\r\nFixes #11984",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "void io.netty.buffer.PoolChunk.initBuf(io.netty.buffer.PooledByteBuf,java.nio.ByteBuffer,long,int,io.netty.buffer.PoolThreadCache)",
            "method_name_cc": "void io.netty.buffer.PoolChunk<T>.initBuf(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity, PoolThreadCache threadCache)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "void io.netty.buffer.PoolChunk<T>.initBuf(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity, PoolThreadCache threadCache)",
            "previous_method_pd": "void io.netty.buffer.PoolChunk.initBuf(io.netty.buffer.PooledByteBuf,java.nio.ByteBuffer,long,int,io.netty.buffer.PoolThreadCache)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "d60ea595bcd2399530d8becbced45df0b9b22aa5",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.9411045802842976,
                "p_value": 0.6425600630728416,
                "effect_size": -0.05731225296442688,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 44,
                    "after": 46
                }
            }
        },
        {
            "commit_message": "Make \"pinned memory\" from PooledByteBufAllocator reflect buffers in use (#11990)\n\nMotivation:\r\nThe pinned memory accounting was being done from a bad place.\r\nNamely, it was being done at the same time as the PoolChunk free memory accounting was being done.\r\nThat means the thread local caching was messing up the accuracy of the numbers.\r\n\r\nModification:\r\nMove pinned memory accounting to the PooledByteBuf init and deallocation methods, so it's tied to the buffer life cycle.\r\n\r\nResult:\r\nThe pinned memory accounting is updated as part of the pooled buffer life cycle, and is no longer being tricked by the activities of the thread-local buffer cache.\r\n\r\nFixes #11984",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "protected final void io.netty.buffer.PooledByteBuf.deallocate()",
            "method_name_cc": "protected final void io.netty.buffer.PooledByteBuf<T>.deallocate()",
            "file": "buffer/src/main/java/io/netty/buffer/PooledByteBuf.java",
            "previous_method_cc": "protected final void io.netty.buffer.PooledByteBuf<T>.deallocate()",
            "previous_method_pd": "protected final void io.netty.buffer.PooledByteBuf.deallocate()",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PooledByteBuf.java",
            "previous_commit": "d60ea595bcd2399530d8becbced45df0b9b22aa5",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 1.2210228278180852,
                "p_value": 1.2988532779445581e-181,
                "effect_size": -0.010743718440289181,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 4846285,
                    "after": 4695527
                }
            }
        },
        {
            "commit_message": "Make \"pinned memory\" from PooledByteBufAllocator reflect buffers in use (#11990)\n\nMotivation:\r\nThe pinned memory accounting was being done from a bad place.\r\nNamely, it was being done at the same time as the PoolChunk free memory accounting was being done.\r\nThat means the thread local caching was messing up the accuracy of the numbers.\r\n\r\nModification:\r\nMove pinned memory accounting to the PooledByteBuf init and deallocation methods, so it's tied to the buffer life cycle.\r\n\r\nResult:\r\nThe pinned memory accounting is updated as part of the pooled buffer life cycle, and is no longer being tricked by the activities of the thread-local buffer cache.\r\n\r\nFixes #11984",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "void io.netty.buffer.PoolChunk.free(long,int,java.nio.ByteBuffer)",
            "method_name_cc": "void io.netty.buffer.PoolChunk<T>.free(long handle, int normCapacity, ByteBuffer nioBuffer)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "void io.netty.buffer.PoolChunk<T>.free(long handle, int normCapacity, ByteBuffer nioBuffer)",
            "previous_method_pd": "void io.netty.buffer.PoolChunk.free(long,int,java.nio.ByteBuffer)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "d60ea595bcd2399530d8becbced45df0b9b22aa5",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 9.583333333333334,
                "p_value": 0.49010202126501656,
                "effect_size": 0.09603174603174604,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 35,
                    "after": 36
                }
            }
        }
    ],
    "afb475dabd5ca9eaa94ccf07f0ecd8431db008ba": [
        {
            "commit_message": "Properly free magazine chunks and avoid orphaned magazines (#14334)\n\nMotivation:\r\nWhen the AdaptivePoolingAllocator is finalized, it will attempt to\r\nrelease all chunks and free all magazines. However, when chunks are\r\nreleased, they tend to want to return to their magazines or the central\r\nqueue for reuse. We must prevent chunks from escaping death in this way,\r\nin the case of finalization.\r\n\r\nThere is another problem, produced by magazine array resizing, which\r\nturns out to have a solution closely related to the above: The magazines\r\narray is indexed into by thread-id modulo the array length. When the\r\narray length changes, so potentially does the preferred locality of each\r\nthread accessing the array. This can cause some magazines that were\r\npreviously used often, to no longer be accessed. This can leave unused\r\nchunks tied up in unused magazines, wasting memory as a result.\r\n\r\nModification:\r\nFirst of all, a volatile `freed` field is added to the\r\nAdaptivePoolingAllocator which, if true, will bar adding chunks to the\r\ncentral queue. When chunks are denied entrance to the central queue,\r\nthey will deallocate their memory.\r\n\r\nBefore chunks attempt to add themselves to the central queue, however,\r\nthey will try to add themselves to nextInLine for their respective\r\nmagazines. A new MAGAZINE_FREED sentinel object now marks freed\r\nmagazines in the nextInLine field, preventing chunks from being added\r\nthere. The field is modified using getAndSet atomic operations, and thus\r\nmay briefly show different values. Code has been added to repair these\r\ncases, restoring the freed status, and releasing any chunks that might\r\nhave been added. This also means the `Magazine.allocate` method can now\r\nfail, so it now returns the boolean status, similarly to `tryAllocate`.\r\nIt's a pretty rare data-race, but it's not impossible due to changes\r\ndescribed later.\r\n\r\nThe freeing of magazines now need to happen before the releasing of all\r\nchunks, so the `AdaptivePoolingAllocator.free` has been modified to\r\nfirst set the `freed` field, preventing chunks from being added to the\r\ncentral queue. Then free magazines, putting them into the freed state\r\nand preventing chunks from getting stowed in the `current` and\r\n`nextInLine` fields. Finally, any remaining chunks are pulled from the\r\ncentral queue and released. Since we now know they have nowhere else to\r\ngo, we are certain their memory will be released.\r\n\r\nLastly, the problem of potentially orphaned magazines is addressed.\r\nInstead of simply extending the existing magazine array (leaving any\r\nexisting magazines at their current index), we now allocate a new array\r\nof all new magazines. Then we free all the old magazines, which will\r\nsend their chunks (at least any next-in-line chunks) to the central\r\nqueue. When the new magazines gets used, they will pull chunks from the\r\ncentral queue for reuse at that time. This means that any magazine array\r\nindexes that are not used, will now no longer be holding to any chunks\r\nfrom before the resize. It also means that magazines can be freed\r\nconcurrently with allocation (though each magazine is individually\r\nprotected by their lock) and deallocation (which is truly concurrent).\r\nSince the magazines array now contain all-new magazines, we loose all\r\nthe allocation size statistics we've built up. This can cause the\r\nmagazines to prefer less-than-ideal chunk sizes. We alleviate some of\r\nthat by preserving the shared preferred chunk size across array resizes.\r\nThis will also prevent some churn from chunks being released and finding\r\ntheir size deviating too much from the preferred chunk size. This is\r\nimportant as many of the chunks obtained from the central queue will be\r\nsized according to the pre-array-resize preferred chunk size.\r\n\r\nThe `PooledByteBufAllocatorTest` was changed slightly, so it now\r\ncaptures the stack trace of where the test thread gets stuck, in case of\r\na timeout. During the development of this PR, a bug caused an infinite\r\nloop in the finalizer thread, which in turn caused the otherwise\r\nunrelated PooledByteBufAllocatorTests to time out.\r\n\r\nResult:\r\nWe get more robust freeing of chunks when the AdaptivePoolingAllocator\r\nis finalized. We also avoid spending memory on any magazines orphaned by\r\nresizes.\r\n\r\nA consequence of this, however, is that resizes are slightly more\r\ndisruptive. The new magazines have all their statistics reset, and they\r\nall have to visit the central queue to obtain chunks. The central queue\r\nmight also not be big enough to hold all the chunks for reuse, which can\r\ncause some memory churn.\r\n\r\n---------\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorConcurrentBenchmark.allocateReleaseAdaptive",
            "method_name_pd": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int)",
            "method_name_cc": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int currentLength)",
            "file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_method_cc": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int currentLength)",
            "previous_method_pd": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_commit": "5a9b28a4157f79bb69331b0979e73c2eb8b2bb3f",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "regression",
                "median_change_percentage": 3713.957800511509,
                "p_value": 1.0717250865394344e-11,
                "effect_size": -0.7334104938271605,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 144,
                    "after": 36
                }
            }
        },
        {
            "commit_message": "Properly free magazine chunks and avoid orphaned magazines (#14334)\n\nMotivation:\r\nWhen the AdaptivePoolingAllocator is finalized, it will attempt to\r\nrelease all chunks and free all magazines. However, when chunks are\r\nreleased, they tend to want to return to their magazines or the central\r\nqueue for reuse. We must prevent chunks from escaping death in this way,\r\nin the case of finalization.\r\n\r\nThere is another problem, produced by magazine array resizing, which\r\nturns out to have a solution closely related to the above: The magazines\r\narray is indexed into by thread-id modulo the array length. When the\r\narray length changes, so potentially does the preferred locality of each\r\nthread accessing the array. This can cause some magazines that were\r\npreviously used often, to no longer be accessed. This can leave unused\r\nchunks tied up in unused magazines, wasting memory as a result.\r\n\r\nModification:\r\nFirst of all, a volatile `freed` field is added to the\r\nAdaptivePoolingAllocator which, if true, will bar adding chunks to the\r\ncentral queue. When chunks are denied entrance to the central queue,\r\nthey will deallocate their memory.\r\n\r\nBefore chunks attempt to add themselves to the central queue, however,\r\nthey will try to add themselves to nextInLine for their respective\r\nmagazines. A new MAGAZINE_FREED sentinel object now marks freed\r\nmagazines in the nextInLine field, preventing chunks from being added\r\nthere. The field is modified using getAndSet atomic operations, and thus\r\nmay briefly show different values. Code has been added to repair these\r\ncases, restoring the freed status, and releasing any chunks that might\r\nhave been added. This also means the `Magazine.allocate` method can now\r\nfail, so it now returns the boolean status, similarly to `tryAllocate`.\r\nIt's a pretty rare data-race, but it's not impossible due to changes\r\ndescribed later.\r\n\r\nThe freeing of magazines now need to happen before the releasing of all\r\nchunks, so the `AdaptivePoolingAllocator.free` has been modified to\r\nfirst set the `freed` field, preventing chunks from being added to the\r\ncentral queue. Then free magazines, putting them into the freed state\r\nand preventing chunks from getting stowed in the `current` and\r\n`nextInLine` fields. Finally, any remaining chunks are pulled from the\r\ncentral queue and released. Since we now know they have nowhere else to\r\ngo, we are certain their memory will be released.\r\n\r\nLastly, the problem of potentially orphaned magazines is addressed.\r\nInstead of simply extending the existing magazine array (leaving any\r\nexisting magazines at their current index), we now allocate a new array\r\nof all new magazines. Then we free all the old magazines, which will\r\nsend their chunks (at least any next-in-line chunks) to the central\r\nqueue. When the new magazines gets used, they will pull chunks from the\r\ncentral queue for reuse at that time. This means that any magazine array\r\nindexes that are not used, will now no longer be holding to any chunks\r\nfrom before the resize. It also means that magazines can be freed\r\nconcurrently with allocation (though each magazine is individually\r\nprotected by their lock) and deallocation (which is truly concurrent).\r\nSince the magazines array now contain all-new magazines, we loose all\r\nthe allocation size statistics we've built up. This can cause the\r\nmagazines to prefer less-than-ideal chunk sizes. We alleviate some of\r\nthat by preserving the shared preferred chunk size across array resizes.\r\nThis will also prevent some churn from chunks being released and finding\r\ntheir size deviating too much from the preferred chunk size. This is\r\nimportant as many of the chunks obtained from the central queue will be\r\nsized according to the pre-array-resize preferred chunk size.\r\n\r\nThe `PooledByteBufAllocatorTest` was changed slightly, so it now\r\ncaptures the stack trace of where the test thread gets stuck, in case of\r\na timeout. During the development of this PR, a bug caused an infinite\r\nloop in the finalizer thread, which in turn caused the otherwise\r\nunrelated PooledByteBufAllocatorTests to time out.\r\n\r\nResult:\r\nWe get more robust freeing of chunks when the AdaptivePoolingAllocator\r\nis finalized. We also avoid spending memory on any magazines orphaned by\r\nresizes.\r\n\r\nA consequence of this, however, is that resizes are slightly more\r\ndisruptive. The new magazines have all their statistics reset, and they\r\nall have to visit the central queue to obtain chunks. The central queue\r\nmight also not be big enough to hold all the chunks for reuse, which can\r\ncause some memory churn.\r\n\r\n---------\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorConcurrentBenchmark.allocateReleaseAdaptive",
            "method_name_pd": "private boolean io.netty.buffer.AdaptivePoolingAllocator.offerToQueue(io.netty.buffer.AdaptivePoolingAllocator$Chunk)",
            "method_name_cc": "private boolean io.netty.buffer.AdaptivePoolingAllocator.offerToQueue(Chunk buffer)",
            "file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_method_cc": "private boolean io.netty.buffer.AdaptivePoolingAllocator.offerToQueue(Chunk buffer)",
            "previous_method_pd": "private boolean io.netty.buffer.AdaptivePoolingAllocator.offerToQueue(io.netty.buffer.AdaptivePoolingAllocator$Chunk)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_commit": "5a9b28a4157f79bb69331b0979e73c2eb8b2bb3f",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -98.9110477999367,
                "p_value": 0.0005319643543088469,
                "effect_size": 1.0,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 4,
                    "after": 1837957
                }
            }
        }
    ],
    "343879818495a6179e397f32034d6122980232ef": [
        {
            "commit_message": "AdaptivePoolingAllocator EventLoop Magazine's affinity (#14017)\n\nMotivation:\r\n\r\nAdaptivePoolingAllocator uses some shared Magazines hoping thread's id\r\ndistribution to improve contended behaviour, but event loops threads can\r\njust uses their own Magazine(s) and save 2 atomic operations (write\r\nlock/unlock) in the hot path, further improving performance.\r\n\r\nModification:\r\n\r\nImplements dedicated event loop Magazines\r\n\r\nResult:\r\n\r\nBetter allocation performance for event loop threads",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorConcurrentBenchmark.allocateReleaseAdaptive",
            "method_name_pd": "private io.netty.buffer.AdaptivePoolingAllocator$AdaptiveByteBuf io.netty.buffer.AdaptivePoolingAllocator.allocate(int,int,java.lang.Thread,io.netty.buffer.AdaptivePoolingAllocator$AdaptiveByteBuf)",
            "method_name_cc": "private AdaptiveByteBuf io.netty.buffer.AdaptivePoolingAllocator.allocate(int size, int maxCapacity, Thread currentThread, AdaptiveByteBuf buf)",
            "file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_method_cc": "private AdaptiveByteBuf io.netty.buffer.AdaptivePoolingAllocator.allocate(int size, int maxCapacity, Thread currentThread, AdaptiveByteBuf buf)",
            "previous_method_pd": "private io.netty.buffer.AdaptivePoolingAllocator$AdaptiveByteBuf io.netty.buffer.AdaptivePoolingAllocator.allocate(int,int,java.lang.Thread,io.netty.buffer.AdaptivePoolingAllocator$AdaptiveByteBuf)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_commit": "2e413d6c73aac00d4541bab119c7a2c330bf8235",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 3.4246575342465753,
                "p_value": 0.0,
                "effect_size": -0.017244719412962153,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 41043128,
                    "after": 32694414
                }
            }
        }
    ],
    "e21caf11d94d96657d140914ff65a62cf24e81ee": [
        {
            "commit_message": "Fix ArrayIndexOutOfBounds: 39 from PoolArena.findSubpagePoolHead (#11939)\n\n\r\nMotivation:\r\nWe were getting occasional reports of an ArrayIndexOutOfBounds from PoolArena.findSubpagePoolHead, which always happened at index 39.\r\nThe sub-page size index array is 39 entries in length, so this access was one past the end.\r\nThis should not happen, because a size that *would* compute to index 39, would be a normal-sized allocation (rather than a small one) and thus not use sub-pages at all.\r\nThe reason this occurred, is because the \"handle\" associated with the allocation indicated that it was small, and thus upon freeing we would access the sub-page array, but the specific index was computed from the normalized allocation size, which was \"normal\" instead of \"small\".\r\nThis happened because of a use-after-free issue in PoolThreadCache, where the entire state of Entry objects were captured prior to return the entry to the recycler *except* for the normCapacity field.\r\nThe normCapacity field is what becomes the normSize down the stack, and accessing this field after a recycle could cause the access to race with a concurrent allocation.\r\nSo if the allocation was originally small and using sub-pages, then we would capture a sub-page handle, then recycle the entry object, which then got used in a normal-sized allocation, and *then* we read the normCapacity field of this other allocation.\r\n\r\nModification:\r\nThe fix is to capture the normCapacity field before calling Entry.recycle() in PoolThreadCache.freeEntry.\r\nA couple of assertions have also been added, to possibly capture bugs like this at an earlier point in the execution.\r\n\r\nResult:\r\nWe should no longer get this particular ArrayIndexOutOfBoundsException.\r\n",
            "benchmark": "io.netty.microbench.buffer.PooledByteBufAllocatorBenchmark.allocateAndFree",
            "method_name_pd": "private void io.netty.buffer.PooledByteBuf.init0(io.netty.buffer.PoolChunk,java.nio.ByteBuffer,long,int,int,int,io.netty.buffer.PoolThreadCache)",
            "method_name_cc": "private void io.netty.buffer.PooledByteBuf<T>.init0(PoolChunk<T> chunk, ByteBuffer nioBuffer, long handle, int offset, int length, int maxLength, PoolThreadCache cache)",
            "file": "buffer/src/main/java/io/netty/buffer/PooledByteBuf.java",
            "previous_method_cc": "private void io.netty.buffer.PooledByteBuf<T>.init0(PoolChunk<T> chunk, ByteBuffer nioBuffer, long handle, int offset, int length, int maxLength, PoolThreadCache cache)",
            "previous_method_pd": "private void io.netty.buffer.PooledByteBuf.init0(io.netty.buffer.PoolChunk,java.nio.ByteBuffer,long,int,int,int,io.netty.buffer.PoolThreadCache)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PooledByteBuf.java",
            "previous_commit": "16f31f83f2b17dc9f450943bf84192cd28874e42",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.6707317073170732,
                "p_value": 0.0,
                "effect_size": -0.05108288993343852,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 36431227,
                    "after": 35949011
                }
            }
        }
    ],
    "ef1f637b0f9979d98dbb0f3e5281d7272012c76d": [
        {
            "commit_message": "Fix runPendingTask for re-registered embedded event loop (#11715)\n\nMotivation:\r\nCurrently, if an `EmbeddedChannel` is re-registered to another `EmbeddedEventLoop` and we send some task to execute then calling `runPendingTasks` will not execute it.\r\n\r\nModification:\r\nDelegate `runPendingTasks` to a registered `EmbededEventLoop` otherwise use internal.\r\n\r\nResult:\r\n\r\nProper handling pending tasks for re-registered `EmbededChannel`.\r\n",
            "benchmark": "io.netty.microbench.channel.DefaultChannelPipelineBenchmark.propagateEvent",
            "method_name_pd": "public void io.netty.channel.embedded.EmbeddedChannel.runPendingTasks()",
            "method_name_cc": "public void io.netty.channel.embedded.EmbeddedChannel.runPendingTasks()",
            "file": "transport/src/main/java/io/netty/channel/embedded/EmbeddedChannel.java",
            "previous_method_cc": "public void io.netty.channel.embedded.EmbeddedChannel.runPendingTasks()",
            "previous_method_pd": "public void io.netty.channel.embedded.EmbeddedChannel.runPendingTasks()",
            "previous_file": "transport/src/main/java/io/netty/channel/embedded/EmbeddedChannel.java",
            "previous_commit": "6604ff261da4878dc6c1c824041739215d2a08cc",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 4.9079754601226995,
                "p_value": 0.0,
                "effect_size": -0.1454841307235612,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 37727064,
                    "after": 35186786
                }
            }
        }
    ],
    "f5185ed73b347ba684eef2348622030b5cbe99cf": [
        {
            "commit_message": "Release message before notify promise (#10726)\n\nMotivation:\r\n\r\nWe should preferable always release the message before we notify the promise. Thhis has a few advantages:\r\n\r\n - Release memory as soon as possible\r\n - Listeners observe the \"more correct\" reference count\r\n\r\nModifications:\r\n\r\nRelease message before fail the promises\r\n\r\nResult:\r\n\r\nFaster releasing of resources. This came up in https://github.com/netty/netty/issues/10723",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "private static boolean io.netty.channel.AbstractChannelHandlerContext.safeExecute(io.netty.util.concurrent.EventExecutor,java.lang.Runnable,io.netty.channel.ChannelPromise,java.lang.Object,boolean)",
            "method_name_cc": "private static boolean io.netty.channel.AbstractChannelHandlerContext.safeExecute(EventExecutor executor, Runnable runnable, ChannelPromise promise, Object msg, boolean lazy)",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "private static boolean io.netty.channel.AbstractChannelHandlerContext.safeExecute(EventExecutor executor, Runnable runnable, ChannelPromise promise, Object msg, boolean lazy)",
            "previous_method_pd": "private static boolean io.netty.channel.AbstractChannelHandlerContext.safeExecute(io.netty.util.concurrent.EventExecutor,java.lang.Runnable,io.netty.channel.ChannelPromise,java.lang.Object,boolean)",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "4ecd78e1044f8874b2f78d1e9b40283d6b62541a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 2.711496746203905,
                "p_value": 0.0,
                "effect_size": -0.09815716340792409,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 2907154,
                    "after": 2806346
                }
            }
        }
    ],
    "005a6a4e7b3632d6719640eac621690d3268fd1f": [
        {
            "commit_message": "Correctly encode result even if no timeout is used (#12283)\n\n\r\nMotivation:\r\n\r\n86004b7303621784f7ec8850323d9a707f17f9f8 did introduce a change to reduc the syscalls but missed to correctly encode the result in the case of no timeout used.\r\n\r\nModifications:\r\n\r\nCorrectly shift the result\r\n\r\nResult:\r\n\r\nCorrectly behaviour even when no timeout is used.  Fixes #12280\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "static long io.netty.channel.epoll.Native.epollWait(io.netty.channel.unix.FileDescriptor,io.netty.channel.epoll.EpollEventArray,io.netty.channel.unix.FileDescriptor,int,int,long) throws java.io.IOException",
            "method_name_cc": "static long io.netty.channel.epoll.Native.epollWait(FileDescriptor epollFd, EpollEventArray events, FileDescriptor timerFd, int timeoutSec, int timeoutNs, long millisThreshold)",
            "file": "transport-classes-epoll/src/main/java/io/netty/channel/epoll/Native.java",
            "previous_method_cc": "static long io.netty.channel.epoll.Native.epollWait(FileDescriptor epollFd, EpollEventArray events, FileDescriptor timerFd, int timeoutSec, int timeoutNs, long millisThreshold)",
            "previous_method_pd": "static long io.netty.channel.epoll.Native.epollWait(io.netty.channel.unix.FileDescriptor,io.netty.channel.epoll.EpollEventArray,io.netty.channel.unix.FileDescriptor,int,int,long) throws java.io.IOException",
            "previous_file": "transport-classes-epoll/src/main/java/io/netty/channel/epoll/Native.java",
            "previous_commit": "5e23212172a761c416ec682c55f462852c381e92",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.0738255033557047,
                "p_value": 0.0,
                "effect_size": 0.024104167212409364,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 5958786,
                    "after": 5973980
                }
            }
        }
    ],
    "9ec938c78faf75230d24c0a30c037a66f8ccee90": [
        {
            "commit_message": "Avoid slow type checks against promises on outbound buffer's progress (#13225)\n\n\r\nMotivation:\r\n\r\nChannelOutboundBuffer's progress perform expensive type checks that can reduce scalability or just performing wasteful operations over common Netty types. This behaviour pop-up in few real-cases, but sadly it cannot be captured easily by java profilers due to https://github.com/jvm-profiling-tools/async-profiler/issues/673\r\n\r\nModification:\r\n\r\nPrefer direct class checks for void promises and guarding Netty types by using concrete class type checks over interface type checks, that will be left to user-defined promises instead.\r\n\r\nResult:\r\n\r\nFaster type checks for Netty types and faster outbound buffer progress's performance.\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public void io.netty.channel.ChannelOutboundBuffer.progress(long)",
            "method_name_cc": "public void io.netty.channel.ChannelOutboundBuffer.progress(long amount)",
            "file": "transport/src/main/java/io/netty/channel/ChannelOutboundBuffer.java",
            "previous_method_cc": "public void io.netty.channel.ChannelOutboundBuffer.progress(long amount)",
            "previous_method_pd": "public void io.netty.channel.ChannelOutboundBuffer.progress(long)",
            "previous_file": "transport/src/main/java/io/netty/channel/ChannelOutboundBuffer.java",
            "previous_commit": "ebb30dbe19a3d39be09195210f9acfd23803289b",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 2.7463651050080773,
                "p_value": 0.0,
                "effect_size": -0.07669047794902577,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 4490013,
                    "after": 3798420
                }
            }
        }
    ],
    "4e439264df0523fb6efce5f8f6c7c7fa74addd07": [
        {
            "commit_message": "Exception from release should not shadow encode exception (#12500)\n\nMotivation:\r\nSince release may throw, we can end up shadowing a root cause exception if we release from a finally-clause.\r\n\r\nModification:\r\nIn MessageToMessageEncoder, if encode() throws an exception, we release using safeRelease(), which will not throw.\r\nOtherwise we release with release() like usual.\r\n\r\nResult:\r\nExceptions from encode() in MessageToMessageEncoder can no longer be shadowed by exceptions from release().\r\n\r\nFixes #12499",
            "benchmark": "io.netty.microbench.http.HttpObjectEncoderBenchmark.fullMessage",
            "method_name_pd": "public void io.netty.handler.codec.MessageToMessageEncoder.write(io.netty.channel.ChannelHandlerContext,java.lang.Object,io.netty.channel.ChannelPromise) throws java.lang.Exception",
            "method_name_cc": "public void io.netty.handler.codec.MessageToMessageEncoder<I>.write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)",
            "file": "codec/src/main/java/io/netty/handler/codec/MessageToMessageEncoder.java",
            "previous_method_cc": "public void io.netty.handler.codec.MessageToMessageEncoder<I>.write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)",
            "previous_method_pd": "public void io.netty.handler.codec.MessageToMessageEncoder.write(io.netty.channel.ChannelHandlerContext,java.lang.Object,io.netty.channel.ChannelPromise) throws java.lang.Exception",
            "previous_file": "codec/src/main/java/io/netty/handler/codec/MessageToMessageEncoder.java",
            "previous_commit": "c6c3bc606d4e716cf5a08ab68eb950ebb8f989b1",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 1.0869565217391304,
                "p_value": 0.0,
                "effect_size": -0.04546516856293781,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 153006304,
                    "after": 152386504
                }
            }
        }
    ],
    "23c19b2b764d49437c49653121c8185130814033": [
        {
            "commit_message": "Prepare for unsafe memory access deprecated for removal (#14090)\n\nMotivation:\r\nJava 23 will introduce JEP 471 (https://openjdk.org/jeps/471) which\r\ndeprecates all unsafe memory access methods for removal.\r\n\r\nThe JEP also starts the removal phase, by introducing a new\r\n`--sun-misc-unsafe-memory-access={allow|warn|debug|deny}` command line\r\noption. Initially, unsafe memory access will be allowed, but will in\r\nfuture Java versions produce warnings, and then eventually denying\r\naccess by default. When access is denied, then calling the unsafe memory\r\naccess methods will produce an `UnsupportedOperationException`.\r\n\r\nModification:\r\nInclude the value of `--sun-misc-unsafe-memory-access` in the\r\nconsideration of explicit-no-unsafe computation. The command line value\r\nis available as the `sun.misc.unsafe.memory.access` system property. If\r\nthe value is not either \"allow\" or unspecified, then unsafe is\r\nexplicitly turned off.\r\n\r\nAdd many more tests to the unsafe availability, probing for all the\r\nunsafe memory access methods we use, and also testing some of them with\r\ndirect calls.\r\n\r\nResult:\r\nWe should hopefully not see any warnings, or \"NoSuchMethodErrors\", in\r\nthe future.",
            "benchmark": "io.netty.util.AsciiStringCaseConversionBenchmark.toLowerCase",
            "method_name_pd": "private static java.lang.Throwable io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0()",
            "method_name_cc": "private static Throwable io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0()",
            "file": "common/src/main/java/io/netty/util/internal/PlatformDependent0.java",
            "previous_method_cc": "private static Throwable io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0()",
            "previous_method_pd": "private static java.lang.Throwable io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0()",
            "previous_file": "common/src/main/java/io/netty/util/internal/PlatformDependent0.java",
            "previous_commit": "20a11b32f00a3d119bd2840e0963c3e9688b73a7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -2.581141151784967,
                "p_value": 0.3923324003499018,
                "effect_size": 0.10640495867768596,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 44,
                    "after": 44
                }
            }
        },
        {
            "commit_message": "Prepare for unsafe memory access deprecated for removal (#14090)\n\nMotivation:\r\nJava 23 will introduce JEP 471 (https://openjdk.org/jeps/471) which\r\ndeprecates all unsafe memory access methods for removal.\r\n\r\nThe JEP also starts the removal phase, by introducing a new\r\n`--sun-misc-unsafe-memory-access={allow|warn|debug|deny}` command line\r\noption. Initially, unsafe memory access will be allowed, but will in\r\nfuture Java versions produce warnings, and then eventually denying\r\naccess by default. When access is denied, then calling the unsafe memory\r\naccess methods will produce an `UnsupportedOperationException`.\r\n\r\nModification:\r\nInclude the value of `--sun-misc-unsafe-memory-access` in the\r\nconsideration of explicit-no-unsafe computation. The command line value\r\nis available as the `sun.misc.unsafe.memory.access` system property. If\r\nthe value is not either \"allow\" or unspecified, then unsafe is\r\nexplicitly turned off.\r\n\r\nAdd many more tests to the unsafe availability, probing for all the\r\nunsafe memory access methods we use, and also testing some of them with\r\ndirect calls.\r\n\r\nResult:\r\nWe should hopefully not see any warnings, or \"NoSuchMethodErrors\", in\r\nthe future.",
            "benchmark": "io.netty.util.AsciiStringCaseConversionBenchmark.toLowerCase",
            "method_name_pd": "public static int io.netty.util.internal.PlatformDependent.getInt(byte[],int)",
            "method_name_cc": "public static int io.netty.util.internal.PlatformDependent.getInt(byte[] data, int index)",
            "file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_method_cc": "public static int io.netty.util.internal.PlatformDependent.getInt(byte[] data, int index)",
            "previous_method_pd": "public static int io.netty.util.internal.PlatformDependent.getInt(byte[],int)",
            "previous_file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_commit": "20a11b32f00a3d119bd2840e0963c3e9688b73a7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.0,
                "p_value": 2.1939279325318586e-264,
                "effect_size": -0.013984439516256277,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3743094,
                    "after": 4563967
                }
            }
        },
        {
            "commit_message": "Prepare for unsafe memory access deprecated for removal (#14090)\n\nMotivation:\r\nJava 23 will introduce JEP 471 (https://openjdk.org/jeps/471) which\r\ndeprecates all unsafe memory access methods for removal.\r\n\r\nThe JEP also starts the removal phase, by introducing a new\r\n`--sun-misc-unsafe-memory-access={allow|warn|debug|deny}` command line\r\noption. Initially, unsafe memory access will be allowed, but will in\r\nfuture Java versions produce warnings, and then eventually denying\r\naccess by default. When access is denied, then calling the unsafe memory\r\naccess methods will produce an `UnsupportedOperationException`.\r\n\r\nModification:\r\nInclude the value of `--sun-misc-unsafe-memory-access` in the\r\nconsideration of explicit-no-unsafe computation. The command line value\r\nis available as the `sun.misc.unsafe.memory.access` system property. If\r\nthe value is not either \"allow\" or unspecified, then unsafe is\r\nexplicitly turned off.\r\n\r\nAdd many more tests to the unsafe availability, probing for all the\r\nunsafe memory access methods we use, and also testing some of them with\r\ndirect calls.\r\n\r\nResult:\r\nWe should hopefully not see any warnings, or \"NoSuchMethodErrors\", in\r\nthe future.",
            "benchmark": "io.netty.util.AsciiStringCaseConversionBenchmark.toLowerCase",
            "method_name_pd": "public static byte io.netty.util.internal.PlatformDependent.getByte(byte[],int)",
            "method_name_cc": "public static byte io.netty.util.internal.PlatformDependent.getByte(byte[] data, int index)",
            "file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_method_cc": "public static byte io.netty.util.internal.PlatformDependent.getByte(byte[] data, int index)",
            "previous_method_pd": "public static byte io.netty.util.internal.PlatformDependent.getByte(byte[],int)",
            "previous_file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_commit": "20a11b32f00a3d119bd2840e0963c3e9688b73a7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.6097560975609756,
                "p_value": 0.0,
                "effect_size": -0.019346077536138862,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3322841,
                    "after": 4077286
                }
            }
        },
        {
            "commit_message": "Prepare for unsafe memory access deprecated for removal (#14090)\n\nMotivation:\r\nJava 23 will introduce JEP 471 (https://openjdk.org/jeps/471) which\r\ndeprecates all unsafe memory access methods for removal.\r\n\r\nThe JEP also starts the removal phase, by introducing a new\r\n`--sun-misc-unsafe-memory-access={allow|warn|debug|deny}` command line\r\noption. Initially, unsafe memory access will be allowed, but will in\r\nfuture Java versions produce warnings, and then eventually denying\r\naccess by default. When access is denied, then calling the unsafe memory\r\naccess methods will produce an `UnsupportedOperationException`.\r\n\r\nModification:\r\nInclude the value of `--sun-misc-unsafe-memory-access` in the\r\nconsideration of explicit-no-unsafe computation. The command line value\r\nis available as the `sun.misc.unsafe.memory.access` system property. If\r\nthe value is not either \"allow\" or unspecified, then unsafe is\r\nexplicitly turned off.\r\n\r\nAdd many more tests to the unsafe availability, probing for all the\r\nunsafe memory access methods we use, and also testing some of them with\r\ndirect calls.\r\n\r\nResult:\r\nWe should hopefully not see any warnings, or \"NoSuchMethodErrors\", in\r\nthe future.",
            "benchmark": "io.netty.util.AsciiStringCaseConversionBenchmark.toLowerCase",
            "method_name_pd": "public static short io.netty.util.internal.PlatformDependent.getShort(byte[],int)",
            "method_name_cc": "public static short io.netty.util.internal.PlatformDependent.getShort(byte[] data, int index)",
            "file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_method_cc": "public static short io.netty.util.internal.PlatformDependent.getShort(byte[] data, int index)",
            "previous_method_pd": "public static short io.netty.util.internal.PlatformDependent.getShort(byte[],int)",
            "previous_file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_commit": "20a11b32f00a3d119bd2840e0963c3e9688b73a7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.0,
                "p_value": 0.0,
                "effect_size": -0.02154156143811594,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1929647,
                    "after": 2337146
                }
            }
        },
        {
            "commit_message": "Prepare for unsafe memory access deprecated for removal (#14090)\n\nMotivation:\r\nJava 23 will introduce JEP 471 (https://openjdk.org/jeps/471) which\r\ndeprecates all unsafe memory access methods for removal.\r\n\r\nThe JEP also starts the removal phase, by introducing a new\r\n`--sun-misc-unsafe-memory-access={allow|warn|debug|deny}` command line\r\noption. Initially, unsafe memory access will be allowed, but will in\r\nfuture Java versions produce warnings, and then eventually denying\r\naccess by default. When access is denied, then calling the unsafe memory\r\naccess methods will produce an `UnsupportedOperationException`.\r\n\r\nModification:\r\nInclude the value of `--sun-misc-unsafe-memory-access` in the\r\nconsideration of explicit-no-unsafe computation. The command line value\r\nis available as the `sun.misc.unsafe.memory.access` system property. If\r\nthe value is not either \"allow\" or unspecified, then unsafe is\r\nexplicitly turned off.\r\n\r\nAdd many more tests to the unsafe availability, probing for all the\r\nunsafe memory access methods we use, and also testing some of them with\r\ndirect calls.\r\n\r\nResult:\r\nWe should hopefully not see any warnings, or \"NoSuchMethodErrors\", in\r\nthe future.",
            "benchmark": "io.netty.util.AsciiStringCaseConversionBenchmark.toLowerCase",
            "method_name_pd": "public static long io.netty.util.internal.PlatformDependent.getLong(byte[],int)",
            "method_name_cc": "public static long io.netty.util.internal.PlatformDependent.getLong(byte[] data, int index)",
            "file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_method_cc": "public static long io.netty.util.internal.PlatformDependent.getLong(byte[] data, int index)",
            "previous_method_pd": "public static long io.netty.util.internal.PlatformDependent.getLong(byte[],int)",
            "previous_file": "common/src/main/java/io/netty/util/internal/PlatformDependent.java",
            "previous_commit": "20a11b32f00a3d119bd2840e0963c3e9688b73a7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -2.4096385542168677,
                "p_value": 0.0,
                "effect_size": 0.08413920096735376,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 17816171,
                    "after": 17948742
                }
            }
        }
    ],
    "caca5e5a1e19a26a3cff3560b79e7ade18398540": [
        {
            "commit_message": "When read PoolSubpage's variant fields, it should lock on PoolSubpage's head lock, instead of PoolArena's lock (#13626)\n\nMotivation:\r\n\r\nWhen we read `PoolSubpage`'s variant fields:`doNotDestroy` and\r\n`numAvail`, we should lock on `PoolSubpage`'s head subpage, instead of\r\n`PoolArena`'s lock.\r\n\r\nBecause the writing on `doNotDestroy` and `numAvail` is always under\r\n`PoolSubpage`'s head subpage lock.\r\n\r\nModification:\r\n\r\n1. Introduced a `int headIndex` field in `PoolSubpage` to locate the\r\nhead subpage, lock on `PoolSubpage`'s head subpage instead of\r\n`PoolArena`'s lock.\r\n2. This also help to locate head subpage when doing `bytebuf` release.\r\nFixed [13625](https://github.com/netty/netty/issues/13625).\r\n\r\nResult:\r\n\r\nSee above.\r\n\r\n---------\r\n\r\nCo-authored-by: laosijikaichele <laosijikaichele>\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "void io.netty.buffer.PoolChunk.initBufWithSubpage(io.netty.buffer.PooledByteBuf,java.nio.ByteBuffer,long,int,io.netty.buffer.PoolThreadCache)",
            "method_name_cc": "void io.netty.buffer.PoolChunk<T>.initBufWithSubpage(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity, PoolThreadCache threadCache)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "void io.netty.buffer.PoolChunk<T>.initBufWithSubpage(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity, PoolThreadCache threadCache)",
            "previous_method_pd": "void io.netty.buffer.PoolChunk.initBufWithSubpage(io.netty.buffer.PooledByteBuf,java.nio.ByteBuffer,long,int,io.netty.buffer.PoolThreadCache)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "d97f2a5606aaccf7494ff29d7229be1349fe746a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -3.944444444444444,
                "p_value": 0.0,
                "effect_size": 0.24221727764102782,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3200724,
                    "after": 3659667
                }
            }
        },
        {
            "commit_message": "When read PoolSubpage's variant fields, it should lock on PoolSubpage's head lock, instead of PoolArena's lock (#13626)\n\nMotivation:\r\n\r\nWhen we read `PoolSubpage`'s variant fields:`doNotDestroy` and\r\n`numAvail`, we should lock on `PoolSubpage`'s head subpage, instead of\r\n`PoolArena`'s lock.\r\n\r\nBecause the writing on `doNotDestroy` and `numAvail` is always under\r\n`PoolSubpage`'s head subpage lock.\r\n\r\nModification:\r\n\r\n1. Introduced a `int headIndex` field in `PoolSubpage` to locate the\r\nhead subpage, lock on `PoolSubpage`'s head subpage instead of\r\n`PoolArena`'s lock.\r\n2. This also help to locate head subpage when doing `bytebuf` release.\r\nFixed [13625](https://github.com/netty/netty/issues/13625).\r\n\r\nResult:\r\n\r\nSee above.\r\n\r\n---------\r\n\r\nCo-authored-by: laosijikaichele <laosijikaichele>\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "boolean io.netty.buffer.PoolChunk.allocate(io.netty.buffer.PooledByteBuf,int,int,io.netty.buffer.PoolThreadCache)",
            "method_name_cc": "boolean io.netty.buffer.PoolChunk<T>.allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "boolean io.netty.buffer.PoolChunk<T>.allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache)",
            "previous_method_pd": "boolean io.netty.buffer.PoolChunk.allocate(io.netty.buffer.PooledByteBuf,int,int,io.netty.buffer.PoolThreadCache)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "d97f2a5606aaccf7494ff29d7229be1349fe746a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 5.502036230866452,
                "p_value": 0.9762828489184295,
                "effect_size": 0.004232804232804233,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 42,
                    "after": 45
                }
            }
        },
        {
            "commit_message": "When read PoolSubpage's variant fields, it should lock on PoolSubpage's head lock, instead of PoolArena's lock (#13626)\n\nMotivation:\r\n\r\nWhen we read `PoolSubpage`'s variant fields:`doNotDestroy` and\r\n`numAvail`, we should lock on `PoolSubpage`'s head subpage, instead of\r\n`PoolArena`'s lock.\r\n\r\nBecause the writing on `doNotDestroy` and `numAvail` is always under\r\n`PoolSubpage`'s head subpage lock.\r\n\r\nModification:\r\n\r\n1. Introduced a `int headIndex` field in `PoolSubpage` to locate the\r\nhead subpage, lock on `PoolSubpage`'s head subpage instead of\r\n`PoolArena`'s lock.\r\n2. This also help to locate head subpage when doing `bytebuf` release.\r\nFixed [13625](https://github.com/netty/netty/issues/13625).\r\n\r\nResult:\r\n\r\nSee above.\r\n\r\n---------\r\n\r\nCo-authored-by: laosijikaichele <laosijikaichele>\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "void io.netty.buffer.PoolChunk.free(long,int,java.nio.ByteBuffer)",
            "method_name_cc": "void io.netty.buffer.PoolChunk<T>.free(long handle, int normCapacity, ByteBuffer nioBuffer)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "void io.netty.buffer.PoolChunk<T>.free(long handle, int normCapacity, ByteBuffer nioBuffer)",
            "previous_method_pd": "void io.netty.buffer.PoolChunk.free(long,int,java.nio.ByteBuffer)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "d97f2a5606aaccf7494ff29d7229be1349fe746a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -26.689774696707108,
                "p_value": 6.78671538345852e-06,
                "effect_size": 0.6008316008316008,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 39,
                    "after": 37
                }
            }
        }
    ],
    "42926695861c012ee6153e6bc8c4846bd4b923e9": [
        {
            "commit_message": "Replace stdlib write/read with send/recv (Fixes #12673) (#12679)\n\nMotivation:\r\n\r\nThe performance Unix write/read paths is more involved (and slower) then the specialized socket send/rcv ones.\r\n\r\nModification:\r\n\r\nReplace Unix write/read paths with send/recv\r\n\r\nResult:\r\n\r\nBetter performance for single buffer send/recv",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doWriteBytes(io.netty.channel.ChannelOutboundBuffer,io.netty.buffer.ByteBuf) throws java.lang.Exception",
            "method_name_cc": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doWriteBytes(ChannelOutboundBuffer in, ByteBuf buf)",
            "file": "transport-classes-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java",
            "previous_method_cc": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doWriteBytes(ChannelOutboundBuffer in, ByteBuf buf)",
            "previous_method_pd": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doWriteBytes(io.netty.channel.ChannelOutboundBuffer,io.netty.buffer.ByteBuf) throws java.lang.Exception",
            "previous_file": "transport-classes-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java",
            "previous_commit": "b7ecda0759087b970260e841bbd65aa7b85d7b66",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -3.1510015408320493,
                "p_value": 0.0,
                "effect_size": 0.08680947271955076,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3827246,
                    "after": 3833116
                }
            }
        },
        {
            "commit_message": "Replace stdlib write/read with send/recv (Fixes #12673) (#12679)\n\nMotivation:\r\n\r\nThe performance Unix write/read paths is more involved (and slower) then the specialized socket send/rcv ones.\r\n\r\nModification:\r\n\r\nReplace Unix write/read paths with send/recv\r\n\r\nResult:\r\n\r\nBetter performance for single buffer send/recv",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doReadBytes(io.netty.buffer.ByteBuf) throws java.lang.Exception",
            "method_name_cc": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doReadBytes(ByteBuf byteBuf)",
            "file": "transport-classes-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java",
            "previous_method_cc": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doReadBytes(ByteBuf byteBuf)",
            "previous_method_pd": "protected final int io.netty.channel.epoll.AbstractEpollChannel.doReadBytes(io.netty.buffer.ByteBuf) throws java.lang.Exception",
            "previous_file": "transport-classes-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java",
            "previous_commit": "b7ecda0759087b970260e841bbd65aa7b85d7b66",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -6.685236768802229,
                "p_value": 0.0,
                "effect_size": 0.5106052711589357,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3382845,
                    "after": 3334349
                }
            }
        }
    ],
    "8f7ef1cabb5442584e56a9e79bcb9696bc572a94": [
        {
            "commit_message": "Skip execution of Channel*Handler method if annotated with @Skip and \u2026 (#8988)\n\n\r\nMotivation:\r\n\r\nInvoking ChannelHandlers is not free and can result in some overhead when the ChannelPipeline becomes very long. This is especially true if most handlers will just forward the call to the next handler in the pipeline. When the user extends Channel*HandlerAdapter we can easily detect if can just skip the handler and invoke the next handler in the pipeline directly. This reduce the overhead of dispatch but also reduce the call-stack in many cases.\r\n\r\nThis backports https://github.com/netty/netty/pull/8723 and https://github.com/netty/netty/pull/8987 to 4.1\r\n\r\nModifications:\r\n\r\nDetect if we can skip the handler when walking the pipeline.\r\n\r\nResult:\r\n\r\nReduce overhead for long pipelines.\r\n\r\nBenchmark                                       (extraHandlers)   Mode  Cnt       Score      Error  Units\r\nDefaultChannelPipelineBenchmark.propagateEventOld             4  thrpt   10  267313.031 \u00b1 9131.140  ops/s\r\nDefaultChannelPipelineBenchmark.propagateEvent                4  thrpt   10  824825.673 \u00b1 12727.594  ops/s\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "method_name_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "previous_method_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "c3c05e85701c60c46303f1f4c3b6c65c64a56ad7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -59.46941783345615,
                "p_value": 0.0,
                "effect_size": 0.5575670708497465,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 266170,
                    "after": 234923
                }
            }
        },
        {
            "commit_message": "Skip execution of Channel*Handler method if annotated with @Skip and \u2026 (#8988)\n\n\r\nMotivation:\r\n\r\nInvoking ChannelHandlers is not free and can result in some overhead when the ChannelPipeline becomes very long. This is especially true if most handlers will just forward the call to the next handler in the pipeline. When the user extends Channel*HandlerAdapter we can easily detect if can just skip the handler and invoke the next handler in the pipeline directly. This reduce the overhead of dispatch but also reduce the call-stack in many cases.\r\n\r\nThis backports https://github.com/netty/netty/pull/8723 and https://github.com/netty/netty/pull/8987 to 4.1\r\n\r\nModifications:\r\n\r\nDetect if we can skip the handler when walking the pipeline.\r\n\r\nResult:\r\n\r\nReduce overhead for long pipelines.\r\n\r\nBenchmark                                       (extraHandlers)   Mode  Cnt       Score      Error  Units\r\nDefaultChannelPipelineBenchmark.propagateEventOld             4  thrpt   10  267313.031 \u00b1 9131.140  ops/s\r\nDefaultChannelPipelineBenchmark.propagateEvent                4  thrpt   10  824825.673 \u00b1 12727.594  ops/s\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete()",
            "method_name_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete()",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete()",
            "previous_method_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.fireChannelReadComplete()",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "c3c05e85701c60c46303f1f4c3b6c65c64a56ad7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -38.356924784901466,
                "p_value": 0.0,
                "effect_size": 0.5185306441830523,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 217487,
                    "after": 240343
                }
            }
        },
        {
            "commit_message": "Skip execution of Channel*Handler method if annotated with @Skip and \u2026 (#8988)\n\n\r\nMotivation:\r\n\r\nInvoking ChannelHandlers is not free and can result in some overhead when the ChannelPipeline becomes very long. This is especially true if most handlers will just forward the call to the next handler in the pipeline. When the user extends Channel*HandlerAdapter we can easily detect if can just skip the handler and invoke the next handler in the pipeline directly. This reduce the overhead of dispatch but also reduce the call-stack in many cases.\r\n\r\nThis backports https://github.com/netty/netty/pull/8723 and https://github.com/netty/netty/pull/8987 to 4.1\r\n\r\nModifications:\r\n\r\nDetect if we can skip the handler when walking the pipeline.\r\n\r\nResult:\r\n\r\nReduce overhead for long pipelines.\r\n\r\nBenchmark                                       (extraHandlers)   Mode  Cnt       Score      Error  Units\r\nDefaultChannelPipelineBenchmark.propagateEventOld             4  thrpt   10  267313.031 \u00b1 9131.140  ops/s\r\nDefaultChannelPipelineBenchmark.propagateEvent                4  thrpt   10  824825.673 \u00b1 12727.594  ops/s\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "private void io.netty.channel.AbstractChannelHandlerContext.write(java.lang.Object,boolean,io.netty.channel.ChannelPromise)",
            "method_name_cc": "private void io.netty.channel.AbstractChannelHandlerContext.write(Object msg, boolean flush, ChannelPromise promise)",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "private void io.netty.channel.AbstractChannelHandlerContext.write(Object msg, boolean flush, ChannelPromise promise)",
            "previous_method_pd": "private void io.netty.channel.AbstractChannelHandlerContext.write(java.lang.Object,boolean,io.netty.channel.ChannelPromise)",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "c3c05e85701c60c46303f1f4c3b6c65c64a56ad7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -8.360369353631146,
                "p_value": 0.0,
                "effect_size": 0.1194275441903951,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 257838,
                    "after": 264286
                }
            }
        },
        {
            "commit_message": "Skip execution of Channel*Handler method if annotated with @Skip and \u2026 (#8988)\n\n\r\nMotivation:\r\n\r\nInvoking ChannelHandlers is not free and can result in some overhead when the ChannelPipeline becomes very long. This is especially true if most handlers will just forward the call to the next handler in the pipeline. When the user extends Channel*HandlerAdapter we can easily detect if can just skip the handler and invoke the next handler in the pipeline directly. This reduce the overhead of dispatch but also reduce the call-stack in many cases.\r\n\r\nThis backports https://github.com/netty/netty/pull/8723 and https://github.com/netty/netty/pull/8987 to 4.1\r\n\r\nModifications:\r\n\r\nDetect if we can skip the handler when walking the pipeline.\r\n\r\nResult:\r\n\r\nReduce overhead for long pipelines.\r\n\r\nBenchmark                                       (extraHandlers)   Mode  Cnt       Score      Error  Units\r\nDefaultChannelPipelineBenchmark.propagateEventOld             4  thrpt   10  267313.031 \u00b1 9131.140  ops/s\r\nDefaultChannelPipelineBenchmark.propagateEvent                4  thrpt   10  824825.673 \u00b1 12727.594  ops/s\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "method_name_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "previous_method_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "c3c05e85701c60c46303f1f4c3b6c65c64a56ad7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.6518424396442184,
                "p_value": 0.0,
                "effect_size": 0.08176796880334239,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 282416,
                    "after": 276012
                }
            }
        }
    ],
    "b409f8e7fa70da80d9801737e051c860aa979f13": [
        {
            "commit_message": "Revert \"Epoll: Avoid redundant EPOLL_CTL_MOD calls (#9397)\"\n\nThis reverts commit 873988676a2b1bb9cc6e5c1a80e5b27725b1d75c.\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "void io.netty.channel.epoll.EpollEventLoop.modify(io.netty.channel.epoll.AbstractEpollChannel) throws java.io.IOException",
            "method_name_cc": "void io.netty.channel.epoll.EpollEventLoop.modify(AbstractEpollChannel ch)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_method_cc": "void io.netty.channel.epoll.EpollEventLoop.modify(AbstractEpollChannel ch)",
            "previous_method_pd": "void io.netty.channel.epoll.EpollEventLoop.modify(io.netty.channel.epoll.AbstractEpollChannel) throws java.io.IOException",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_commit": "8280252d0e80e5e844215234732a7cda4862e260",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -38.57549883176782,
                "p_value": 0.10933952528379773,
                "effect_size": 0.47619047619047616,
                "effect_size_interpretation": "large",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 6,
                    "after": 14
                }
            }
        },
        {
            "commit_message": "Revert \"Epoll: Avoid redundant EPOLL_CTL_MOD calls (#9397)\"\n\nThis reverts commit 873988676a2b1bb9cc6e5c1a80e5b27725b1d75c.\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "void io.netty.channel.epoll.AbstractEpollChannel.setFlag(int) throws java.io.IOException",
            "method_name_cc": "void io.netty.channel.epoll.AbstractEpollChannel.setFlag(int flag)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java",
            "previous_method_cc": "void io.netty.channel.epoll.AbstractEpollChannel.setFlag(int flag)",
            "previous_method_pd": "void io.netty.channel.epoll.AbstractEpollChannel.setFlag(int) throws java.io.IOException",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/AbstractEpollChannel.java",
            "previous_commit": "8280252d0e80e5e844215234732a7cda4862e260",
            "performance_diff": -0.0,
            "significance": {}
        },
        {
            "commit_message": "Revert \"Epoll: Avoid redundant EPOLL_CTL_MOD calls (#9397)\"\n\nThis reverts commit 873988676a2b1bb9cc6e5c1a80e5b27725b1d75c.\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "void io.netty.channel.epoll.EpollEventLoop.remove(io.netty.channel.epoll.AbstractEpollChannel) throws java.io.IOException",
            "method_name_cc": "void io.netty.channel.epoll.EpollEventLoop.remove(AbstractEpollChannel ch)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_method_cc": "void io.netty.channel.epoll.EpollEventLoop.remove(AbstractEpollChannel ch)",
            "previous_method_pd": "void io.netty.channel.epoll.EpollEventLoop.remove(io.netty.channel.epoll.AbstractEpollChannel) throws java.io.IOException",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_commit": "8280252d0e80e5e844215234732a7cda4862e260",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -6.869786368260428,
                "p_value": 0.43825357196871007,
                "effect_size": 0.15432098765432098,
                "effect_size_interpretation": "small",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 18,
                    "after": 18
                }
            }
        }
    ],
    "b4e3c12b8e8e984ba65330dd6dc34a4b3d07a25a": [
        {
            "commit_message": "Http2ConnectionHandler to allow decoupling close(..) from GOAWAY graceful close (#9094)\n\nMotivation:\r\nHttp2ConnectionHandler#close(..) always runs the GOAWAY and graceful close\r\nlogic. This coupling means that a user would have to override\r\nHttp2ConnectionHandler#close(..) to modify the behavior, and the\r\nHttp2FrameCodec and Http2MultiplexCodec are not extendable so you cannot\r\noverride at this layer. Ideally we can totally decouple the close(..) of the\r\ntransport and the GOAWAY graceful closure process completely, but to preserve\r\nbackwards compatibility we can add an opt-out option to decouple where the\r\napplication is responsible for sending a GOAWAY with error code equal to\r\nNO_ERROR as described in https://tools.ietf.org/html/rfc7540#section-6.8 in\r\norder to initiate graceful close.\r\n\r\nModifications:\r\n- Http2ConnectionHandler supports an additional boolean constructor argument to\r\nopt out of close(..) going through the graceful close path.\r\n- Http2FrameCodecBuilder and Http2MultiplexCodec expose\r\n gracefulShutdownTimeoutMillis but do not hook them up properly. Since these\r\nare already exposed we should hook them up and make sure the timeout is applied\r\nproperly.\r\n- Http2ConnectionHandler's goAway(..) method from Http2LifecycleManager should\r\ninitiate the graceful closure process after writing a GOAWAY frame if the error\r\ncode is NO_ERROR. This means that writing a Http2GoAwayFrame from\r\nHttp2FrameCodec will initiate graceful close.\r\n\r\nResult:\r\nHttp2ConnectionHandler#close(..) can now be decoupled from the graceful close\r\nprocess, and immediately close the underlying transport if desired.",
            "benchmark": "io.netty.microbench.http2.NoPriorityByteDistributionBenchmark.write",
            "method_name_pd": "protected io.netty.handler.codec.http2.Http2ConnectionHandler io.netty.handler.codec.http2.Http2ConnectionHandlerBuilder.build(io.netty.handler.codec.http2.Http2ConnectionDecoder,io.netty.handler.codec.http2.Http2ConnectionEncoder,io.netty.handler.codec.http2.Http2Settings)",
            "method_name_cc": "protected Http2ConnectionHandler io.netty.handler.codec.http2.Http2ConnectionHandlerBuilder.build(Http2ConnectionDecoder decoder, Http2ConnectionEncoder encoder, Http2Settings initialSettings)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/Http2ConnectionHandlerBuilder.java",
            "previous_method_cc": "protected Http2ConnectionHandler io.netty.handler.codec.http2.Http2ConnectionHandlerBuilder.build(Http2ConnectionDecoder decoder, Http2ConnectionEncoder encoder, Http2Settings initialSettings)",
            "previous_method_pd": "protected io.netty.handler.codec.http2.Http2ConnectionHandler io.netty.handler.codec.http2.Http2ConnectionHandlerBuilder.build(io.netty.handler.codec.http2.Http2ConnectionDecoder,io.netty.handler.codec.http2.Http2ConnectionEncoder,io.netty.handler.codec.http2.Http2Settings)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/Http2ConnectionHandlerBuilder.java",
            "previous_commit": "00a9a25f29cf07728794089affdd735af29209de",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 2.1705602448873216,
                "p_value": 0.6564206123913285,
                "effect_size": -0.06172839506172839,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 36,
                    "after": 36
                }
            }
        }
    ],
    "ab8c4f22c6bc11b7082fddfc6890fd02f30d5524": [
        {
            "commit_message": "Improve performance of HPACK static table lookup (#10840)\n\n\r\nMotivation:\r\n\r\nHPACK static table is organized in a way that fields with the same\r\nname are sequential. Which means when doing sequential scan we can\r\nshort-circuit scan on name mismatch.\r\n\r\nModifications:\r\n\r\n* `HpackStaticTable.getIndexIndensitive` returns -1 on name mismatch\r\nrather than keep scanning.\r\n* `HpackStaticTable` statically defined max position in the array\r\nwhere name duplication is possible (after the given index there's\r\nno need to check for other fields with the same name)\r\n* Benchmark for different lookup patterns\r\n\r\nResult:\r\n\r\nBetter HPACK static table lookup performance.\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndex(java.lang.CharSequence)",
            "method_name_cc": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndex(CharSequence name)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackStaticTable.java",
            "previous_method_cc": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndex(CharSequence name)",
            "previous_method_pd": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndex(java.lang.CharSequence)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackStaticTable.java",
            "previous_commit": "3e8e52725bbd9d999873880956bc8f241372daa8",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -3.565274545680635,
                "p_value": 0.007445766570840785,
                "effect_size": 0.04718708866350088,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 2158,
                    "after": 2132
                }
            }
        },
        {
            "commit_message": "Improve performance of HPACK static table lookup (#10840)\n\n\r\nMotivation:\r\n\r\nHPACK static table is organized in a way that fields with the same\r\nname are sequential. Which means when doing sequential scan we can\r\nshort-circuit scan on name mismatch.\r\n\r\nModifications:\r\n\r\n* `HpackStaticTable.getIndexIndensitive` returns -1 on name mismatch\r\nrather than keep scanning.\r\n* `HpackStaticTable` statically defined max position in the array\r\nwhere name duplication is possible (after the given index there's\r\nno need to check for other fields with the same name)\r\n* Benchmark for different lookup patterns\r\n\r\nResult:\r\n\r\nBetter HPACK static table lookup performance.\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private int io.netty.handler.codec.http2.HpackEncoder.getIndex(java.lang.CharSequence)",
            "method_name_cc": "private int io.netty.handler.codec.http2.HpackEncoder.getIndex(CharSequence name)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_method_cc": "private int io.netty.handler.codec.http2.HpackEncoder.getIndex(CharSequence name)",
            "previous_method_pd": "private int io.netty.handler.codec.http2.HpackEncoder.getIndex(java.lang.CharSequence)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_commit": "3e8e52725bbd9d999873880956bc8f241372daa8",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -3.4009541218957597,
                "p_value": 0.09971286141614108,
                "effect_size": 0.03547811091195481,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 1444,
                    "after": 1428
                }
            }
        },
        {
            "commit_message": "Improve performance of HPACK static table lookup (#10840)\n\n\r\nMotivation:\r\n\r\nHPACK static table is organized in a way that fields with the same\r\nname are sequential. Which means when doing sequential scan we can\r\nshort-circuit scan on name mismatch.\r\n\r\nModifications:\r\n\r\n* `HpackStaticTable.getIndexIndensitive` returns -1 on name mismatch\r\nrather than keep scanning.\r\n* `HpackStaticTable` statically defined max position in the array\r\nwhere name duplication is possible (after the given index there's\r\nno need to check for other fields with the same name)\r\n* Benchmark for different lookup patterns\r\n\r\nResult:\r\n\r\nBetter HPACK static table lookup performance.\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private int io.netty.handler.codec.http2.HpackEncoder.getNameIndex(java.lang.CharSequence)",
            "method_name_cc": "private int io.netty.handler.codec.http2.HpackEncoder.getNameIndex(CharSequence name)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_method_cc": "private int io.netty.handler.codec.http2.HpackEncoder.getNameIndex(CharSequence name)",
            "previous_method_pd": "private int io.netty.handler.codec.http2.HpackEncoder.getNameIndex(java.lang.CharSequence)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_commit": "3e8e52725bbd9d999873880956bc8f241372daa8",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -2.894737755502258,
                "p_value": 0.04962231692489956,
                "effect_size": 0.04246483656013465,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1436,
                    "after": 1415
                }
            }
        },
        {
            "commit_message": "Improve performance of HPACK static table lookup (#10840)\n\n\r\nMotivation:\r\n\r\nHPACK static table is organized in a way that fields with the same\r\nname are sequential. Which means when doing sequential scan we can\r\nshort-circuit scan on name mismatch.\r\n\r\nModifications:\r\n\r\n* `HpackStaticTable.getIndexIndensitive` returns -1 on name mismatch\r\nrather than keep scanning.\r\n* `HpackStaticTable` statically defined max position in the array\r\nwhere name duplication is possible (after the given index there's\r\nno need to check for other fields with the same name)\r\n* Benchmark for different lookup patterns\r\n\r\nResult:\r\n\r\nBetter HPACK static table lookup performance.\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private void io.netty.handler.codec.http2.HpackEncoder.encodeLiteral(io.netty.buffer.ByteBuf,java.lang.CharSequence,java.lang.CharSequence,io.netty.handler.codec.http2.HpackUtil$IndexType,int)",
            "method_name_cc": "private void io.netty.handler.codec.http2.HpackEncoder.encodeLiteral(ByteBuf out, CharSequence name, CharSequence value, IndexType indexType, int nameIndex)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_method_cc": "private void io.netty.handler.codec.http2.HpackEncoder.encodeLiteral(ByteBuf out, CharSequence name, CharSequence value, IndexType indexType, int nameIndex)",
            "previous_method_pd": "private void io.netty.handler.codec.http2.HpackEncoder.encodeLiteral(io.netty.buffer.ByteBuf,java.lang.CharSequence,java.lang.CharSequence,io.netty.handler.codec.http2.HpackUtil$IndexType,int)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_commit": "3e8e52725bbd9d999873880956bc8f241372daa8",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.3975855951637728,
                "p_value": 0.49119165065852743,
                "effect_size": 0.014951045117715786,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 1412,
                    "after": 1416
                }
            }
        },
        {
            "commit_message": "Improve performance of HPACK static table lookup (#10840)\n\n\r\nMotivation:\r\n\r\nHPACK static table is organized in a way that fields with the same\r\nname are sequential. Which means when doing sequential scan we can\r\nshort-circuit scan on name mismatch.\r\n\r\nModifications:\r\n\r\n* `HpackStaticTable.getIndexIndensitive` returns -1 on name mismatch\r\nrather than keep scanning.\r\n* `HpackStaticTable` statically defined max position in the array\r\nwhere name duplication is possible (after the given index there's\r\nno need to check for other fields with the same name)\r\n* Benchmark for different lookup patterns\r\n\r\nResult:\r\n\r\nBetter HPACK static table lookup performance.\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private void io.netty.handler.codec.http2.HpackEncoder.encodeHeader(io.netty.buffer.ByteBuf,java.lang.CharSequence,java.lang.CharSequence,boolean,long)",
            "method_name_cc": "private void io.netty.handler.codec.http2.HpackEncoder.encodeHeader(ByteBuf out, CharSequence name, CharSequence value, boolean sensitive, long headerSize)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_method_cc": "private void io.netty.handler.codec.http2.HpackEncoder.encodeHeader(ByteBuf out, CharSequence name, CharSequence value, boolean sensitive, long headerSize)",
            "previous_method_pd": "private void io.netty.handler.codec.http2.HpackEncoder.encodeHeader(io.netty.buffer.ByteBuf,java.lang.CharSequence,java.lang.CharSequence,boolean,long)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_commit": "3e8e52725bbd9d999873880956bc8f241372daa8",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -2.815245879376041,
                "p_value": 0.24833849661394825,
                "effect_size": 0.02491752557195284,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 1423,
                    "after": 1440
                }
            }
        },
        {
            "commit_message": "Improve performance of HPACK static table lookup (#10840)\n\n\r\nMotivation:\r\n\r\nHPACK static table is organized in a way that fields with the same\r\nname are sequential. Which means when doing sequential scan we can\r\nshort-circuit scan on name mismatch.\r\n\r\nModifications:\r\n\r\n* `HpackStaticTable.getIndexIndensitive` returns -1 on name mismatch\r\nrather than keep scanning.\r\n* `HpackStaticTable` statically defined max position in the array\r\nwhere name duplication is possible (after the given index there's\r\nno need to check for other fields with the same name)\r\n* Benchmark for different lookup patterns\r\n\r\nResult:\r\n\r\nBetter HPACK static table lookup performance.\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndexInsensitive(java.lang.CharSequence,java.lang.CharSequence)",
            "method_name_cc": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndexInsensitive(CharSequence name, CharSequence value)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackStaticTable.java",
            "previous_method_cc": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndexInsensitive(CharSequence name, CharSequence value)",
            "previous_method_pd": "static int io.netty.handler.codec.http2.HpackStaticTable.getIndexInsensitive(java.lang.CharSequence,java.lang.CharSequence)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackStaticTable.java",
            "previous_commit": "3e8e52725bbd9d999873880956bc8f241372daa8",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.0475511174512601,
                "p_value": 0.12116584625085551,
                "effect_size": 0.04729569157287394,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 714,
                    "after": 719
                }
            }
        }
    ],
    "8280252d0e80e5e844215234732a7cda4862e260": [
        {
            "commit_message": "Revert \"Close eventfd shutdown/wakeup race by closely tracking epoll edges (#9535)\"\n\nThis reverts commit 2123fbe495cc86b5a8203a0452ecdd0e5ec8d7c3.\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "static int io.netty.channel.epoll.Native.epollWait(io.netty.channel.unix.FileDescriptor,io.netty.channel.epoll.EpollEventArray,boolean) throws java.io.IOException",
            "method_name_cc": "static int io.netty.channel.epoll.Native.epollWait(FileDescriptor epollFd, EpollEventArray events, boolean immediatePoll)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java",
            "previous_method_cc": "static int io.netty.channel.epoll.Native.epollWait(FileDescriptor epollFd, EpollEventArray events, boolean immediatePoll)",
            "previous_method_pd": "static int io.netty.channel.epoll.Native.epollWait(io.netty.channel.unix.FileDescriptor,io.netty.channel.epoll.EpollEventArray,boolean) throws java.io.IOException",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java",
            "previous_commit": "aef47bec7f0f72d104bf3525aded05d0b8c8e499",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -55.79159743650606,
                "p_value": 0.0,
                "effect_size": 0.9757597380856697,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 284188,
                    "after": 255662
                }
            }
        },
        {
            "commit_message": "Revert \"Close eventfd shutdown/wakeup race by closely tracking epoll edges (#9535)\"\n\nThis reverts commit 2123fbe495cc86b5a8203a0452ecdd0e5ec8d7c3.\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "private boolean io.netty.channel.epoll.EpollEventLoop.processReady(io.netty.channel.epoll.EpollEventArray,int)",
            "method_name_cc": "private boolean io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventArray events, int ready)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_method_cc": "private boolean io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventArray events, int ready)",
            "previous_method_pd": "private boolean io.netty.channel.epoll.EpollEventLoop.processReady(io.netty.channel.epoll.EpollEventArray,int)",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_commit": "aef47bec7f0f72d104bf3525aded05d0b8c8e499",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.4292300599354542,
                "p_value": 0.0,
                "effect_size": 0.09707462027167602,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 249275,
                    "after": 245579
                }
            }
        },
        {
            "commit_message": "Revert \"Close eventfd shutdown/wakeup race by closely tracking epoll edges (#9535)\"\n\nThis reverts commit 2123fbe495cc86b5a8203a0452ecdd0e5ec8d7c3.\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "private int io.netty.channel.epoll.EpollEventLoop.epollWait() throws java.io.IOException",
            "method_name_cc": "private int io.netty.channel.epoll.EpollEventLoop.epollWait()",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_method_cc": "private int io.netty.channel.epoll.EpollEventLoop.epollWait()",
            "previous_method_pd": "private int io.netty.channel.epoll.EpollEventLoop.epollWait() throws java.io.IOException",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollEventLoop.java",
            "previous_commit": "aef47bec7f0f72d104bf3525aded05d0b8c8e499",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -25.784455359722624,
                "p_value": 0.0,
                "effect_size": 0.6133807616372283,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 283316,
                    "after": 280615
                }
            }
        }
    ],
    "fe4a59011addc5a556ec882b5795db241f6c77c9": [
        {
            "commit_message": "Do not schedule notify task if there are no listeners attached to the promise. (#8797)\n\nMotivation:\r\n\r\nIf there are no listeners attached to the promise when full-filling it we do not need to schedule a task to notify.\r\n\r\nModifications:\r\n\r\n- Don't schedule a task if there is nothing to notify.\r\n- Add unit tests.\r\n\r\nResult:\r\n\r\nFixes https://github.com/netty/netty/issues/8795.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "private boolean io.netty.util.concurrent.DefaultPromise.setValue0(java.lang.Object)",
            "method_name_cc": "private boolean io.netty.util.concurrent.DefaultPromise<V>.setValue0(Object objResult)",
            "file": "common/src/main/java/io/netty/util/concurrent/DefaultPromise.java",
            "previous_method_cc": "private boolean io.netty.util.concurrent.DefaultPromise<V>.setValue0(Object objResult)",
            "previous_method_pd": "private boolean io.netty.util.concurrent.DefaultPromise.setValue0(java.lang.Object)",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/DefaultPromise.java",
            "previous_commit": "ff7484864b1785103cbc62845ff3a392c93822b7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.0523057876818322,
                "p_value": 0.0,
                "effect_size": 0.11875189846235938,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 276375,
                    "after": 253068
                }
            }
        }
    ],
    "ab8b8ae81b24439ff94085f3f4bd060c172c1712": [
        {
            "commit_message": "Introduce SslContextOption which can be used for \"optional\" features \u2026 (#10981)\n\n\r\nMotivation:\r\n\r\nSome of the features we want to support can only be supported by some of the SslContext implementations. We should allow to configure these in a consistent way the same way as we do it with Channel / ChannelOption\r\n\r\nModifications:\r\n\r\n- Add SslContextOption and add builder methods that take these\r\n- Add OpenSslContextOption and define two options there which are specific to openssl\r\n\r\nResult:\r\n\r\nMore flexible configuration and implementation of SslContext\r\n",
            "benchmark": "io.netty.microbench.handler.ssl.SslEngineHandshakeBenchmark.handshake",
            "method_name_pd": "public io.netty.handler.ssl.SslContext io.netty.handler.ssl.SslContextBuilder.build() throws javax.net.ssl.SSLException",
            "method_name_cc": "public SslContext io.netty.handler.ssl.SslContextBuilder.build()",
            "file": "handler/src/main/java/io/netty/handler/ssl/SslContextBuilder.java",
            "previous_method_cc": "public SslContext io.netty.handler.ssl.SslContextBuilder.build()",
            "previous_method_pd": "public io.netty.handler.ssl.SslContext io.netty.handler.ssl.SslContextBuilder.build() throws javax.net.ssl.SSLException",
            "previous_file": "handler/src/main/java/io/netty/handler/ssl/SslContextBuilder.java",
            "previous_commit": "a9a3e2cef1e2ed35b88dce5f5c363158ccb956c7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.0747745552184595,
                "p_value": 0.30593715936537225,
                "effect_size": 0.14814814814814814,
                "effect_size_interpretation": "small",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 36,
                    "after": 30
                }
            }
        }
    ],
    "6e0d22335d3419d91ae60cb40811a0faa25bed50": [
        {
            "commit_message": "Include more details if we throw an IllegalArgumentException because of overflow (#10330)\n\nMotivation:\r\n\r\nWe should include as much details as possible when throwing an IllegalArgumentException because of overflow in CompositeByteBuf\r\n\r\nModifications:\r\n\r\nAdd more details and factor out check into a static method to share code\r\n\r\nResult:\r\n\r\nMake it more clear why an operations failed",
            "benchmark": "io.netty.microbench.search.SearchBenchmark.indexOf",
            "method_name_pd": "private int io.netty.buffer.CompositeByteBuf.addComponent0(boolean,int,io.netty.buffer.ByteBuf)",
            "method_name_cc": "private int io.netty.buffer.CompositeByteBuf.addComponent0(boolean increaseWriterIndex, int cIndex, ByteBuf buffer)",
            "file": "buffer/src/main/java/io/netty/buffer/CompositeByteBuf.java",
            "previous_method_cc": "private int io.netty.buffer.CompositeByteBuf.addComponent0(boolean increaseWriterIndex, int cIndex, ByteBuf buffer)",
            "previous_method_pd": "private int io.netty.buffer.CompositeByteBuf.addComponent0(boolean,int,io.netty.buffer.ByteBuf)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/CompositeByteBuf.java",
            "previous_commit": "bc943808d081f04d64e25d54f042b208b286d7fe",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "regression",
                "median_change_percentage": 41.822829686224146,
                "p_value": 4.342395120179055e-05,
                "effect_size": -0.3282174556213018,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 104,
                    "after": 104
                }
            }
        }
    ],
    "d5fabe78a7b4b7d4124177c0f3dd103b1028c18e": [
        {
            "commit_message": "Utilize i.n.u.internal.ObjectUtil to assert Preconditions (buffer) (#11170) (#11182)\n\nMotivation:\r\n\r\nNullChecks resulting in a NullPointerException or IllegalArgumentException, numeric ranges (>0, >=0) checks, not empty strings/arrays checks must never be anonymous but with the parameter or variable name which is checked. They must be specific and should not be done with an \"OR-Logic\" (if a == null || b == null) throw new NullPointerEx.\r\n\r\nModifications:\r\n\r\n* import static relevant checks\r\n* Replace manual checks with ObjectUtil methods\r\n\r\nResult:\r\n\r\nAll checks needed are done with ObjectUtil, some exception texts are improved.\r\n\r\nFixes #11170\r\n",
            "benchmark": "io.netty.microbench.search.SearchBenchmark.indexOf",
            "method_name_pd": "public static boolean io.netty.buffer.ByteBufUtil.equals(io.netty.buffer.ByteBuf,int,io.netty.buffer.ByteBuf,int,int)",
            "method_name_cc": "public static boolean io.netty.buffer.ByteBufUtil.equals(ByteBuf a, int aStartIndex, ByteBuf b, int bStartIndex, int length)",
            "file": "buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
            "previous_method_cc": "public static boolean io.netty.buffer.ByteBufUtil.equals(ByteBuf a, int aStartIndex, ByteBuf b, int bStartIndex, int length)",
            "previous_method_pd": "public static boolean io.netty.buffer.ByteBufUtil.equals(io.netty.buffer.ByteBuf,int,io.netty.buffer.ByteBuf,int,int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
            "previous_commit": "c3416d8ad2260f3c9bc98a9061d25bba92020f93",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 7.733975323502859,
                "p_value": 0.0,
                "effect_size": -0.05233890429129518,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 4163438,
                    "after": 4149169
                }
            }
        }
    ],
    "737519314153f9146eaf532cd4e945a621cf3fa5": [
        {
            "commit_message": "Don't update state of PromiseCombiner when finish(null) is called (#8843)\n\nMotivation:\r\n\r\nWhen we fail a call to PromiseCombiner.finish(...) because of a null argument we must not update the internal state before throwing.\r\n\r\nModifications:\r\n\r\n- First do the null check and only after we validated that the argument is not null update the internal state\r\n- Add test case.\r\n\r\nModifications:\r\n\r\nDo not mess up internal state of PromiseCombiner when finish(...) is called with a null argument.\r\n\r\nResult:\r\n\r\nAfter your change, what will change.",
            "benchmark": "io.netty.microbench.http.HttpObjectEncoderBenchmark.chunked",
            "method_name_pd": "public void io.netty.util.concurrent.PromiseCombiner.finish(io.netty.util.concurrent.Promise)",
            "method_name_cc": "public void io.netty.util.concurrent.PromiseCombiner.finish(Promise<Void> aggregatePromise)",
            "file": "common/src/main/java/io/netty/util/concurrent/PromiseCombiner.java",
            "previous_method_cc": "public void io.netty.util.concurrent.PromiseCombiner.finish(Promise<Void> aggregatePromise)",
            "previous_method_pd": "public void io.netty.util.concurrent.PromiseCombiner.finish(io.netty.util.concurrent.Promise)",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/PromiseCombiner.java",
            "previous_commit": "4c64c98f348131e0792ba4a92ce3d0003237d56a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -7.483576121108254,
                "p_value": 4.812123866710899e-250,
                "effect_size": 0.036241136704793564,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 577297,
                    "after": 580665
                }
            }
        }
    ],
    "9557c88da2aaa49b3c3fd7525462dc0694681c19": [
        {
            "commit_message": "Add option to HttpObjectDecoder to allow duplicate Content-Lengths (#10349)\n\n\r\nMotivation:\r\n\r\nSince https://github.com/netty/netty/pull/9865 (Netty 4.1.44) the\r\ndefault behavior of the HttpObjectDecoder has been to reject any HTTP\r\nmessage that is found to have multiple Content-Length headers when\r\ndecoding. This behavior is well-justified as per the risks outlined in\r\nhttps://github.com/netty/netty/issues/9861, however, we can see from the\r\ncited RFC section that there are multiple possible options offered for\r\nresponding to this scenario:\r\n\r\n> If a message is received that has multiple Content-Length header\r\n> fields with field-values consisting of the same decimal value, or a\r\n> single Content-Length header field with a field value containing a\r\n> list of identical decimal values (e.g., \"Content-Length: 42, 42\"),\r\n> indicating that duplicate Content-Length header fields have been\r\n> generated or combined by an upstream message processor, then the\r\n> recipient MUST either reject the message as invalid or replace the\r\n> duplicated field-values with a single valid Content-Length field\r\n> containing that decimal value prior to determining the message body\r\n> length or forwarding the message.\r\n\r\nhttps://tools.ietf.org/html/rfc7230#section-3.3.2\r\n\r\nNetty opted for the first option (rejecting as invalid), which seems\r\nlike the safest, but the second option (replacing duplicate values with\r\na single value) is also valid behavior.\r\n\r\nModifications:\r\n\r\n* Introduce \"allowDuplicateContentLengths\" parameter to\r\nHttpObjectDecoder (defaulting to false).\r\n* When set to true, will allow multiple Content-Length headers only if\r\nthey are all the same value. The duplicated field-values will be\r\nreplaced with a single valid Content-Length field.\r\n* Add new parameterized test class for testing different variations of\r\nmultiple Content-Length headers.\r\n\r\nResult:\r\n\r\nThis is a backwards-compatible change with no functional change to the\r\nexisting behavior.\r\n\r\nNote that the existing logic would result in NumberFormatExceptions\r\nfor header values like \"Content-Length: 42, 42\". The new logic correctly\r\nreports these as IllegalArgumentException with the proper error message.\r\n\r\nAdditionally note that this behavior is only applied to HTTP/1.1, but I\r\nsuspect that we may want to expand that to include HTTP/1.0 as well...\r\nThat behavior is not modified here to minimize the scope of this change.\r\n",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "private io.netty.handler.codec.http.HttpObjectDecoder$State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(io.netty.buffer.ByteBuf)",
            "method_name_cc": "private State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(ByteBuf buffer)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_method_cc": "private State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(ByteBuf buffer)",
            "previous_method_pd": "private io.netty.handler.codec.http.HttpObjectDecoder$State io.netty.handler.codec.http.HttpObjectDecoder.readHeaders(io.netty.buffer.ByteBuf)",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_commit": "7a05aa1cf874c49ef07f1f2fd85fe35437642d41",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 1.4008620689655173,
                "p_value": 0.0,
                "effect_size": -0.042507531751072594,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1351840,
                    "after": 1374664
                }
            }
        }
    ],
    "384eaf773cc668979192b8a9537fa5b2b91ce952": [
        {
            "commit_message": "Set keystoreType for JdkSslClientContext Keystores (#9965)\n\nMotivation:\r\n\r\nIn the PR #9003, the issue #8998 was supposedly solved. But actually the fix only made it so the TrustManager can use the specified keystore type instead of also supporting it in the KeyManagerFactory.\r\n\r\nIn my environment, we are using PKCS#11 Keys which are then rejected by the PKCS#12 keystore. A PKCS#12 keystore is created since the keystoreType was set to null by the code from the mentioned PR.\r\n\r\nModification:\r\n\r\nDo not ignore the keystoreType parameter during the creation of the JdkSslClientContext KeyManagerFactory.\r\n\r\nResult:\r\n\r\nFixes #8998.\r\n",
            "benchmark": "io.netty.microbench.handler.ssl.SslEngineHandshakeBenchmark.handshake",
            "method_name_pd": "private static javax.net.ssl.SSLContext io.netty.handler.ssl.JdkSslClientContext.newSSLContext(java.security.Provider,java.security.cert.X509Certificate[],javax.net.ssl.TrustManagerFactory,java.security.cert.X509Certificate[],java.security.PrivateKey,java.lang.String,javax.net.ssl.KeyManagerFactory,long,long,java.lang.String) throws javax.net.ssl.SSLException",
            "method_name_cc": "private static SSLContext io.netty.handler.ssl.JdkSslClientContext.newSSLContext(Provider sslContextProvider, X509Certificate[] trustCertCollection, TrustManagerFactory trustManagerFactory, X509Certificate[] keyCertChain, PrivateKey key, String keyPassword, KeyManagerFactory keyManagerFactory, long sessionCacheSize, long sessionTimeout, String keyStore)",
            "file": "handler/src/main/java/io/netty/handler/ssl/JdkSslClientContext.java",
            "previous_method_cc": "private static SSLContext io.netty.handler.ssl.JdkSslClientContext.newSSLContext(Provider sslContextProvider, X509Certificate[] trustCertCollection, TrustManagerFactory trustManagerFactory, X509Certificate[] keyCertChain, PrivateKey key, String keyPassword, KeyManagerFactory keyManagerFactory, long sessionCacheSize, long sessionTimeout, String keyStore)",
            "previous_method_pd": "private static javax.net.ssl.SSLContext io.netty.handler.ssl.JdkSslClientContext.newSSLContext(java.security.Provider,java.security.cert.X509Certificate[],javax.net.ssl.TrustManagerFactory,java.security.cert.X509Certificate[],java.security.PrivateKey,java.lang.String,javax.net.ssl.KeyManagerFactory,long,long,java.lang.String) throws javax.net.ssl.SSLException",
            "previous_file": "handler/src/main/java/io/netty/handler/ssl/JdkSslClientContext.java",
            "previous_commit": "2023a4f60759772261280159bccb4869e63c14e7",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 3.7482064844941667,
                "p_value": 0.07279149650656339,
                "effect_size": -0.26411290322580644,
                "effect_size_interpretation": "small",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 32,
                    "after": 31
                }
            }
        }
    ],
    "ee7027288ec5f3d688be3cee45a521a5786ccf71": [
        {
            "commit_message": "ByteToMessageDecoder Cumulator improments (#9877)\n\nMotivation:\r\nByteToMessageDecoder's default MERGE_CUMULATOR will allocate a new buffer and\r\ncopy if the refCnt() of the cumulation is > 1. However this is overly\r\nconservative because we maybe able to avoid allocate/copy if the current\r\ncumulation can accommodate the input buffer without a reallocation. Also when the\r\nreallocation and copy does occur the new buffer is sized just large enough to\r\naccommodate the current the current amount of data. If some data remains in the\r\ncumulation after decode this will require a new allocation/copy when more data\r\narrives.\r\n\r\nModifications:\r\n- Use maxFastWritableBytes to avoid allocation/copy if the current buffer can\r\n  accommodate the input data without a reallocation operation.\r\n- Use ByteBufAllocator#calculateNewCapacity(..) to get the size of the buffer\r\n  when a reallocation/copy operation is necessary.\r\n\r\nResult:\r\nByteToMessageDecoder MERGE_CUMULATOR won't allocate/copy if the cumulation\r\nbuffer can accommodate data without a reallocation, and when a reallocation\r\noccurs we are more likely to leave additional space for future data in an effort\r\nto reduce overall reallocations.",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "private static io.netty.buffer.ByteBuf io.netty.handler.codec.ByteToMessageDecoder.expandCumulation(io.netty.buffer.ByteBufAllocator,io.netty.buffer.ByteBuf,io.netty.buffer.ByteBuf)",
            "method_name_cc": "private static ByteBuf io.netty.handler.codec.ByteToMessageDecoder.expandCumulation(ByteBufAllocator alloc, ByteBuf oldCumulation, ByteBuf in)",
            "file": "codec/src/main/java/io/netty/handler/codec/ByteToMessageDecoder.java",
            "previous_method_cc": "static ByteBuf io.netty.handler.codec.ByteToMessageDecoder.expandCumulation(ByteBufAllocator alloc, ByteBuf oldCumulation, ByteBuf in)",
            "previous_method_pd": "static io.netty.buffer.ByteBuf io.netty.handler.codec.ByteToMessageDecoder.expandCumulation(io.netty.buffer.ByteBufAllocator,io.netty.buffer.ByteBuf,io.netty.buffer.ByteBuf)",
            "previous_file": "codec/src/main/java/io/netty/handler/codec/ByteToMessageDecoder.java",
            "previous_commit": "e7091c04d78e29ad8f6843b96f2c47184b03f7a4",
            "performance_diff": 0.03785448816568304,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -2.283619960530025,
                "p_value": 0.0,
                "effect_size": 0.20599715923437595,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1239911,
                    "after": 1110871
                }
            }
        }
    ],
    "b82258b72fdf4c733d9c4a641c6b8725b036485f": [
        {
            "commit_message": "Introduce `needReport` for `ResourceLeakDetector`. (#9910)\n\nMotivation:\r\n\r\nWe can extend `ResourceLeakDetector` through `ResourceLeakDetectorFactory`, and then report the leaked information by covering `reportTracedLeak` and `reportUntracedLeak`. However, the behavior of `reportTracedLeak` and `reportUntracedLeak` is controlled by `logger.isErrorEnabled()`, which is not reasonable. In the case of extending `ResourceLeakDetector`, we sometimes need `needReport` to always return true instead of relying on `logger.isErrorEnabled ()`.\r\n\r\nModification:\r\n\r\nintroduce `needReport` method and let it be `protected`\r\n\r\nResult:\r\n\r\nWe can control the report leak behavior.\r\n",
            "benchmark": "io.netty.microbench.util.ResourceLeakDetectorRecordBenchmark.recordWithHint",
            "method_name_pd": "private void io.netty.util.ResourceLeakDetector.reportLeak()",
            "method_name_cc": "private void io.netty.util.ResourceLeakDetector<T>.reportLeak()",
            "file": "common/src/main/java/io/netty/util/ResourceLeakDetector.java",
            "previous_method_cc": "private void io.netty.util.ResourceLeakDetector<T>.reportLeak()",
            "previous_method_pd": "private void io.netty.util.ResourceLeakDetector.reportLeak()",
            "previous_file": "common/src/main/java/io/netty/util/ResourceLeakDetector.java",
            "previous_commit": "76fb4c894af15cd1e30495a91074b2d95940e451",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.0456553755522826,
                "p_value": 0.0,
                "effect_size": 0.09934321341101884,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 511571,
                    "after": 494544
                }
            }
        }
    ],
    "f17bfd0f64189d91302fbdd15103788bf9eabaa2": [
        {
            "commit_message": "Only use static Exception instances when we can ensure addSuppressed \u2026 (#9152)\n\nMotivation:\r\n\r\nOOME is occurred by increasing suppressedExceptions because other libraries call Throwable#addSuppressed. As we have no control over what other libraries do we need to ensure this can not lead to OOME.\r\n\r\nModifications:\r\n\r\nOnly use static instances of the Exceptions if we can either dissable addSuppressed or we run on java6.\r\n\r\nResult:\r\n\r\nNot possible to OOME because of addSuppressed. Fixes https://github.com/netty/netty/issues/9151.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public final int io.netty.channel.unix.FileDescriptor.writeAddress(long,int,int) throws java.io.IOException",
            "method_name_cc": "public final int io.netty.channel.unix.FileDescriptor.writeAddress(long address, int pos, int limit)",
            "file": "transport-native-unix-common/src/main/java/io/netty/channel/unix/FileDescriptor.java",
            "previous_method_cc": "public final int io.netty.channel.unix.FileDescriptor.writeAddress(long address, int pos, int limit)",
            "previous_method_pd": "public final int io.netty.channel.unix.FileDescriptor.writeAddress(long,int,int) throws java.io.IOException",
            "previous_file": "transport-native-unix-common/src/main/java/io/netty/channel/unix/FileDescriptor.java",
            "previous_commit": "c565805f1b268bba81fe45369babee96856bacf1",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.07448234768359899,
                "p_value": 6.723342782211612e-90,
                "effect_size": -0.03079301474382208,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 281887,
                    "after": 286515
                }
            }
        },
        {
            "commit_message": "Only use static Exception instances when we can ensure addSuppressed \u2026 (#9152)\n\nMotivation:\r\n\r\nOOME is occurred by increasing suppressedExceptions because other libraries call Throwable#addSuppressed. As we have no control over what other libraries do we need to ensure this can not lead to OOME.\r\n\r\nModifications:\r\n\r\nOnly use static instances of the Exceptions if we can either dissable addSuppressed or we run on java6.\r\n\r\nResult:\r\n\r\nNot possible to OOME because of addSuppressed. Fixes https://github.com/netty/netty/issues/9151.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public final int io.netty.channel.unix.FileDescriptor.readAddress(long,int,int) throws java.io.IOException",
            "method_name_cc": "public final int io.netty.channel.unix.FileDescriptor.readAddress(long address, int pos, int limit)",
            "file": "transport-native-unix-common/src/main/java/io/netty/channel/unix/FileDescriptor.java",
            "previous_method_cc": "public final int io.netty.channel.unix.FileDescriptor.readAddress(long address, int pos, int limit)",
            "previous_method_pd": "public final int io.netty.channel.unix.FileDescriptor.readAddress(long,int,int) throws java.io.IOException",
            "previous_file": "transport-native-unix-common/src/main/java/io/netty/channel/unix/FileDescriptor.java",
            "previous_commit": "c565805f1b268bba81fe45369babee96856bacf1",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.4796163069544364,
                "p_value": 5.640662068024691e-72,
                "effect_size": -0.028119897897528296,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 259089,
                    "after": 284893
                }
            }
        }
    ],
    "1039f69e53792ff58f3f61f5ab6f7b89ef1fecf0": [
        {
            "commit_message": "Fix for incorrect values from CompositeByteBuf#component(int) (#9525)\n\nMotivation\r\n\r\nThis is a \"simpler\" alternative to #9416 which fixes the same\r\nCompositeByteBuf bugs described there, originally reported by @jingene\r\nin #9398.\r\n\r\nModifications\r\n- Add fields to Component class for the original buffer along with its\r\nadjustment, which may be different to the already-stored unwrapped\r\nbuffer. Use it in appropriate places to ensure correctness and\r\nequivalent behaviour to that prior to the earlier optimizations\r\n- Add comments explaining purpose of each of the Component fields\r\n- Unwrap more kinds of buffers in newComponent method to extend scope of\r\nthe existing indirection-reduction optimization\r\n- De-duplicate common buffer consolidation logic\r\n- Unit test for the original bug provided by @jingene\r\n\r\nResult\r\n- Correct behaviour / fixed bugs\r\n- Some code deduplication / simplification\r\n- Unwrapping optimization applied to more types of buffers\r\n\r\nThe downside is increased mem footprint from the two new fields, and\r\nadditional allocations in some specific cases, though those should be\r\nrare.\r\n\r\n\r\nCo-authored-by: jingene <jingene0206@gmail.com>",
            "benchmark": "io.netty.buffer.CompositeByteBufRandomAccessBenchmark.setLong",
            "method_name_pd": "private void io.netty.buffer.CompositeByteBuf.consolidateIfNeeded()",
            "method_name_cc": "private void io.netty.buffer.CompositeByteBuf.consolidateIfNeeded()",
            "file": "buffer/src/main/java/io/netty/buffer/CompositeByteBuf.java",
            "previous_method_cc": "private void io.netty.buffer.CompositeByteBuf.consolidateIfNeeded()",
            "previous_method_pd": "private void io.netty.buffer.CompositeByteBuf.consolidateIfNeeded()",
            "previous_file": "buffer/src/main/java/io/netty/buffer/CompositeByteBuf.java",
            "previous_commit": "21b7e29ea7c211bb2b889bae3a0c6c5d9f60fb01",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -36.076498054305624,
                "p_value": 0.03326938587383006,
                "effect_size": 0.42483660130718953,
                "effect_size_interpretation": "medium",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 18,
                    "after": 17
                }
            }
        }
    ],
    "feb804dca8579c93ff3224564aafcf5938bb2c52": [
        {
            "commit_message": "Avoid extra Runnable allocs when scheduling tasks outside event loop (#9744)\n\n\r\nMotivation\r\n\r\nCurrently when future tasks are scheduled via EventExecutors from a\r\ndifferent thread, at least two allocations are performed - the\r\nScheduledFutureTask wrapping the to-be-run task, and a Runnable wrapping\r\nthe action to add to the scheduled task priority queue. The latter can\r\nbe avoided by incorporating this logic into the former.\r\n\r\nModification\r\n\r\n- When scheduling or cancelling a future task from outside the event\r\nloop, enqueue the task itself rather than wrapping in a Runnable\r\n- Have ScheduledFutureTask#run first verify the task's deadline has\r\npassed and if not add or remove it from the scheduledTaskQueue depending\r\non its cancellation state\r\n- Add new outside-event-loop benchmarks to ScheduleFutureTaskBenchmark\r\n\r\nResult\r\n\r\nFewer allocations when scheduling/cancelling future tasks\r\n\r\n\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "static long io.netty.util.concurrent.ScheduledFutureTask.deadlineToDelayNanos(long)",
            "method_name_cc": "static long io.netty.util.concurrent.ScheduledFutureTask<V>.deadlineToDelayNanos(long deadlineNanos)",
            "file": "common/src/main/java/io/netty/util/concurrent/ScheduledFutureTask.java",
            "previous_method_cc": "static long io.netty.util.concurrent.ScheduledFutureTask<V>.deadlineToDelayNanos(long deadlineNanos)",
            "previous_method_pd": "static long io.netty.util.concurrent.ScheduledFutureTask.deadlineToDelayNanos(long)",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/ScheduledFutureTask.java",
            "previous_commit": "17bffce90e2051250be7eea85a3e327717a6aa7f",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -19.295428535942726,
                "p_value": 0.3192845395254462,
                "effect_size": 0.19444444444444445,
                "effect_size_interpretation": "small",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 15,
                    "after": 24
                }
            }
        },
        {
            "commit_message": "Avoid extra Runnable allocs when scheduling tasks outside event loop (#9744)\n\n\r\nMotivation\r\n\r\nCurrently when future tasks are scheduled via EventExecutors from a\r\ndifferent thread, at least two allocations are performed - the\r\nScheduledFutureTask wrapping the to-be-run task, and a Runnable wrapping\r\nthe action to add to the scheduled task priority queue. The latter can\r\nbe avoided by incorporating this logic into the former.\r\n\r\nModification\r\n\r\n- When scheduling or cancelling a future task from outside the event\r\nloop, enqueue the task itself rather than wrapping in a Runnable\r\n- Have ScheduledFutureTask#run first verify the task's deadline has\r\npassed and if not add or remove it from the scheduledTaskQueue depending\r\non its cancellation state\r\n- Add new outside-event-loop benchmarks to ScheduleFutureTaskBenchmark\r\n\r\nResult\r\n\r\nFewer allocations when scheduling/cancelling future tasks\r\n\r\n\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "protected final java.lang.Runnable io.netty.util.concurrent.AbstractScheduledEventExecutor.pollScheduledTask(long)",
            "method_name_cc": "protected final Runnable io.netty.util.concurrent.AbstractScheduledEventExecutor.pollScheduledTask(long nanoTime)",
            "file": "common/src/main/java/io/netty/util/concurrent/AbstractScheduledEventExecutor.java",
            "previous_method_cc": "protected final Runnable io.netty.util.concurrent.AbstractScheduledEventExecutor.pollScheduledTask(long nanoTime)",
            "previous_method_pd": "protected final java.lang.Runnable io.netty.util.concurrent.AbstractScheduledEventExecutor.pollScheduledTask(long)",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/AbstractScheduledEventExecutor.java",
            "previous_commit": "17bffce90e2051250be7eea85a3e327717a6aa7f",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.3744740532959325,
                "p_value": 0.0,
                "effect_size": 0.07235897219709113,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 267674,
                    "after": 271749
                }
            }
        },
        {
            "commit_message": "Avoid extra Runnable allocs when scheduling tasks outside event loop (#9744)\n\n\r\nMotivation\r\n\r\nCurrently when future tasks are scheduled via EventExecutors from a\r\ndifferent thread, at least two allocations are performed - the\r\nScheduledFutureTask wrapping the to-be-run task, and a Runnable wrapping\r\nthe action to add to the scheduled task priority queue. The latter can\r\nbe avoided by incorporating this logic into the former.\r\n\r\nModification\r\n\r\n- When scheduling or cancelling a future task from outside the event\r\nloop, enqueue the task itself rather than wrapping in a Runnable\r\n- Have ScheduledFutureTask#run first verify the task's deadline has\r\npassed and if not add or remove it from the scheduledTaskQueue depending\r\non its cancellation state\r\n- Add new outside-event-loop benchmarks to ScheduleFutureTaskBenchmark\r\n\r\nResult\r\n\r\nFewer allocations when scheduling/cancelling future tasks\r\n\r\n\r\n",
            "benchmark": "io.netty.microbench.channel.DefaultChannelPipelineBenchmark.propagateEvent",
            "method_name_pd": "protected final long io.netty.util.concurrent.AbstractScheduledEventExecutor.nextScheduledTaskNano()",
            "method_name_cc": "protected final long io.netty.util.concurrent.AbstractScheduledEventExecutor.nextScheduledTaskNano()",
            "file": "common/src/main/java/io/netty/util/concurrent/AbstractScheduledEventExecutor.java",
            "previous_method_cc": "protected final long io.netty.util.concurrent.AbstractScheduledEventExecutor.nextScheduledTaskNano()",
            "previous_method_pd": "protected final long io.netty.util.concurrent.AbstractScheduledEventExecutor.nextScheduledTaskNano()",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/AbstractScheduledEventExecutor.java",
            "previous_commit": "17bffce90e2051250be7eea85a3e327717a6aa7f",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -2.8359511343804535,
                "p_value": 2.0847491331724375e-244,
                "effect_size": 0.052543969556485944,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 269199,
                    "after": 269145
                }
            }
        }
    ],
    "c3416d8ad2260f3c9bc98a9061d25bba92020f93": [
        {
            "commit_message": "Utilize i.n.u.internal.ObjectUtil to assert Preconditions (transport*) (#11170) (#11181)\n\nMotivation:\r\n\r\nNullChecks resulting in a NullPointerException or IllegalArgumentException, numeric ranges (>0, >=0) checks, not empty strings/arrays checks must never be anonymous but with the parameter or variable name which is checked. They must be specific and should not be done with an \"OR-Logic\" (if a == null || b == null) throw new NullPointerEx.\r\n\r\nModifications:\r\n\r\n* import static relevant checks\r\n* Replace manual checks with ObjectUtil methods\r\n\r\nResult:\r\n\r\nAll checks needed are done with ObjectUtil, some exception texts are improved.\r\n\r\nFixes #11170\r\n",
            "benchmark": "io.netty.microbench.channel.DefaultChannelPipelineBenchmark.propagateEvent",
            "method_name_pd": "private void io.netty.channel.DefaultChannelConfig.setRecvByteBufAllocator(io.netty.channel.RecvByteBufAllocator,io.netty.channel.ChannelMetadata)",
            "method_name_cc": "private void io.netty.channel.DefaultChannelConfig.setRecvByteBufAllocator(RecvByteBufAllocator allocator, ChannelMetadata metadata)",
            "file": "transport/src/main/java/io/netty/channel/DefaultChannelConfig.java",
            "previous_method_cc": "private void io.netty.channel.DefaultChannelConfig.setRecvByteBufAllocator(RecvByteBufAllocator allocator, ChannelMetadata metadata)",
            "previous_method_pd": "private void io.netty.channel.DefaultChannelConfig.setRecvByteBufAllocator(io.netty.channel.RecvByteBufAllocator,io.netty.channel.ChannelMetadata)",
            "previous_file": "transport/src/main/java/io/netty/channel/DefaultChannelConfig.java",
            "previous_commit": "2f4beae8ecfec25d0504119a7c4881092872e16a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 6.301008579838477,
                "p_value": 0.43573066003173655,
                "effect_size": -0.19444444444444445,
                "effect_size_interpretation": "small",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 12,
                    "after": 12
                }
            }
        }
    ],
    "c41d46111dc37aaf9c8ee7aec162d87221df1d70": [
        {
            "commit_message": "Create bespoke long/long hashmap and long-valued priority queue for PoolChunk (#10826)\n\n\r\nMotivation:\r\nThe uncached access to PoolChunk can be made faster, and avoid allocating boxed Longs, if we have a primitive hash map and priority queue implementation for it.\r\n\r\nModification:\r\nAdd bespoke primitive implementations of a hash map and a priority queue for PoolChunk.\r\nRemove all the long-boxing caused by the previous implementation.\r\nThe hashmap is a linear probing map with a fairly short probe that keeps the search within a couple of cache lines.\r\nThe priority queue is the same binary heap algorithm that's described in Algorithms by Sedgewick and Wayne.\r\nThe implementation avoids the Long boxing by relying on a long[] array.\r\nThis makes the internal-remove method faster, which is an important operation in PoolChunk.\r\n\r\nResult:\r\nRoughly 13% performance uplift in buffer allocations that miss cache.\r\n\r\n",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorBenchmark.defaultPooledDirectAllocAndFree",
            "method_name_pd": "private int io.netty.buffer.PoolChunk.runFirstBestFit(int)",
            "method_name_cc": "private int io.netty.buffer.PoolChunk<T>.runFirstBestFit(int pageIdx)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "private int io.netty.buffer.PoolChunk<T>.runFirstBestFit(int pageIdx)",
            "previous_method_pd": "private int io.netty.buffer.PoolChunk.runFirstBestFit(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "567b46fa0182e5b613ae1c975972a3cfa35c06a4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.5461573442473853,
                "p_value": 0.0,
                "effect_size": 0.10924487019256823,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 291106,
                    "after": 284840
                }
            }
        },
        {
            "commit_message": "Create bespoke long/long hashmap and long-valued priority queue for PoolChunk (#10826)\n\n\r\nMotivation:\r\nThe uncached access to PoolChunk can be made faster, and avoid allocating boxed Longs, if we have a primitive hash map and priority queue implementation for it.\r\n\r\nModification:\r\nAdd bespoke primitive implementations of a hash map and a priority queue for PoolChunk.\r\nRemove all the long-boxing caused by the previous implementation.\r\nThe hashmap is a linear probing map with a fairly short probe that keeps the search within a couple of cache lines.\r\nThe priority queue is the same binary heap algorithm that's described in Algorithms by Sedgewick and Wayne.\r\nThe implementation avoids the Long boxing by relying on a long[] array.\r\nThis makes the internal-remove method faster, which is an important operation in PoolChunk.\r\n\r\nResult:\r\nRoughly 13% performance uplift in buffer allocations that miss cache.\r\n\r\n",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorBenchmark.defaultPooledDirectAllocAndFree",
            "method_name_pd": "private long io.netty.buffer.PoolChunk.allocateRun(int)",
            "method_name_cc": "private long io.netty.buffer.PoolChunk<T>.allocateRun(int runSize)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "private long io.netty.buffer.PoolChunk<T>.allocateRun(int runSize)",
            "previous_method_pd": "private long io.netty.buffer.PoolChunk.allocateRun(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "567b46fa0182e5b613ae1c975972a3cfa35c06a4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -3.9619651347068143,
                "p_value": 0.0,
                "effect_size": 0.15374147146971065,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 312468,
                    "after": 310175
                }
            }
        },
        {
            "commit_message": "Create bespoke long/long hashmap and long-valued priority queue for PoolChunk (#10826)\n\n\r\nMotivation:\r\nThe uncached access to PoolChunk can be made faster, and avoid allocating boxed Longs, if we have a primitive hash map and priority queue implementation for it.\r\n\r\nModification:\r\nAdd bespoke primitive implementations of a hash map and a priority queue for PoolChunk.\r\nRemove all the long-boxing caused by the previous implementation.\r\nThe hashmap is a linear probing map with a fairly short probe that keeps the search within a couple of cache lines.\r\nThe priority queue is the same binary heap algorithm that's described in Algorithms by Sedgewick and Wayne.\r\nThe implementation avoids the Long boxing by relying on a long[] array.\r\nThis makes the internal-remove method faster, which is an important operation in PoolChunk.\r\n\r\nResult:\r\nRoughly 13% performance uplift in buffer allocations that miss cache.\r\n\r\n",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorBenchmark.defaultPooledDirectAllocAndFree",
            "method_name_pd": "private long io.netty.buffer.PoolChunk.collapsePast(long)",
            "method_name_cc": "private long io.netty.buffer.PoolChunk<T>.collapsePast(long handle)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "private long io.netty.buffer.PoolChunk<T>.collapsePast(long handle)",
            "previous_method_pd": "private long io.netty.buffer.PoolChunk.collapsePast(long)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "567b46fa0182e5b613ae1c975972a3cfa35c06a4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -5.419942076954903,
                "p_value": 0.0,
                "effect_size": 0.20244187914858294,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 290969,
                    "after": 281750
                }
            }
        },
        {
            "commit_message": "Create bespoke long/long hashmap and long-valued priority queue for PoolChunk (#10826)\n\n\r\nMotivation:\r\nThe uncached access to PoolChunk can be made faster, and avoid allocating boxed Longs, if we have a primitive hash map and priority queue implementation for it.\r\n\r\nModification:\r\nAdd bespoke primitive implementations of a hash map and a priority queue for PoolChunk.\r\nRemove all the long-boxing caused by the previous implementation.\r\nThe hashmap is a linear probing map with a fairly short probe that keeps the search within a couple of cache lines.\r\nThe priority queue is the same binary heap algorithm that's described in Algorithms by Sedgewick and Wayne.\r\nThe implementation avoids the Long boxing by relying on a long[] array.\r\nThis makes the internal-remove method faster, which is an important operation in PoolChunk.\r\n\r\nResult:\r\nRoughly 13% performance uplift in buffer allocations that miss cache.\r\n\r\n",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorBenchmark.defaultPooledDirectAllocAndFree",
            "method_name_pd": "private long io.netty.buffer.PoolChunk.collapseNext(long)",
            "method_name_cc": "private long io.netty.buffer.PoolChunk<T>.collapseNext(long handle)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "private long io.netty.buffer.PoolChunk<T>.collapseNext(long handle)",
            "previous_method_pd": "private long io.netty.buffer.PoolChunk.collapseNext(long)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "567b46fa0182e5b613ae1c975972a3cfa35c06a4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.4217432052483599,
                "p_value": 0.0,
                "effect_size": 0.06160484679864672,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 248331,
                    "after": 254299
                }
            }
        }
    ],
    "768a8250353d5ab3664f5382b57d0c19a256d68d": [
        {
            "commit_message": "Avoid CancellationException construction in DefaultPromise (#9534)\n\nMotivation\r\n\r\n#9152 reverted some static exception reuse optimizations due to the\r\nproblem with Throwable#addSuppressed() raised in #9151. This introduced\r\na performance issue when promises are cancelled at a high frequency due\r\nto the construction cost of CancellationException at the time that\r\nDefaultPromise#cancel() is called.\r\n\r\nModifications\r\n\r\n- Reinstate the prior static CANCELLATION_CAUSE_HOLDER but use it just\r\nas a sentinel to indicate cancellation, constructing a new\r\nCancellationException only if/when one needs to be explicitly\r\nreturned/thrown\r\n- Subclass CancellationException, overriding fillInStackTrace() to\r\nminimize the construction cost in these cases\r\n\r\nResult\r\n\r\nPromises are much cheaper to cancel. Fixes #9522.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "public java.lang.Throwable io.netty.util.concurrent.DefaultPromise.cause()",
            "method_name_cc": "public Throwable io.netty.util.concurrent.DefaultPromise<V>.cause()",
            "file": "common/src/main/java/io/netty/util/concurrent/DefaultPromise.java",
            "previous_method_cc": "public Throwable io.netty.util.concurrent.DefaultPromise<V>.cause()",
            "previous_method_pd": "public java.lang.Throwable io.netty.util.concurrent.DefaultPromise.cause()",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/DefaultPromise.java",
            "previous_commit": "d446765b8469ca40db40f46e5c637d980b734a8a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -4.514981529621015,
                "p_value": 0.0,
                "effect_size": 0.21277467132711297,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 275362,
                    "after": 282949
                }
            }
        }
    ],
    "f6ea528e0e6fe7d77970a0af18f09820b630fe14": [
        {
            "commit_message": "Refactor SizeClasses to not call private methods in the constructor (#12013)\n\nMotivation:\r\n\r\nCalling non-static methods from within the constructor that belong to the instance is considered a bad practice and can cause bugs. Beside of this it also has the side effect that we can not define all the fields final even tho these are not modified outside of the constructor.\r\n\r\nModifications:\r\n\r\n- Refactor SizeClasses such so it will only use static methods from within its constructor\r\n- Declare everything final that can\r\n- Share some code\r\n\r\nResult:\r\n\r\nCleaner / more optimal code that is also easier to maintain",
            "benchmark": "io.netty.microbench.buffer.PooledByteBufAllocatorBenchmark.allocateAndFree",
            "method_name_pd": "public int io.netty.buffer.SizeClasses.size2SizeIdx(int)",
            "method_name_cc": "public int io.netty.buffer.SizeClasses.size2SizeIdx(int size)",
            "file": "buffer/src/main/java/io/netty/buffer/SizeClasses.java",
            "previous_method_cc": "public int io.netty.buffer.SizeClasses.size2SizeIdx(int size)",
            "previous_method_pd": "public int io.netty.buffer.SizeClasses.size2SizeIdx(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/SizeClasses.java",
            "previous_commit": "982b890095a11242fff0e90558f0f3b883f52bc9",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -11.97129909365559,
                "p_value": 0.0,
                "effect_size": 0.2116590940420316,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 277074,
                    "after": 262235
                }
            }
        }
    ],
    "6b6475fb565551c36f372fe37683d98df6674161": [
        {
            "commit_message": "Prevent ByteToMessageDecoder from overreading when !isAutoRead (#9252)\n\n\r\nMotivation:\r\n\r\nByteToMessageDecoder only looks at the last channelRead() in the batch\r\nof channelRead()-s when determining whether or not it should call\r\nChannelHandlerContext#read() to consume more data when !isAutoRead. This\r\nwill lead to read() calls issued unnecessaily and unprompted if the very\r\nlast channelRead() didn't result in at least one decoded message, even\r\nif there have been messages decoded from other channelRead()-s in the\r\ncurrent batch.\r\n\r\nModifications:\r\n\r\nTrack decode outcomes for the entire batch of channelRead() calls and\r\nonly issue a read in BTMD if the entire batch of channelRead() calls\r\nyielded no complete messages.\r\n\r\nResult:\r\n\r\nByteToMessageDecoder will no longer overread when the very last read\r\nyielded no message, but the batch of reads did.\r\n",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "public void io.netty.handler.codec.ByteToMessageDecoder.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object) throws java.lang.Exception",
            "method_name_cc": "public void io.netty.handler.codec.ByteToMessageDecoder.channelRead(ChannelHandlerContext ctx, Object msg)",
            "file": "codec/src/main/java/io/netty/handler/codec/ByteToMessageDecoder.java",
            "previous_method_cc": "public void io.netty.handler.codec.ByteToMessageDecoder.channelRead(ChannelHandlerContext ctx, Object msg)",
            "previous_method_pd": "public void io.netty.handler.codec.ByteToMessageDecoder.channelRead(io.netty.channel.ChannelHandlerContext,java.lang.Object) throws java.lang.Exception",
            "previous_file": "codec/src/main/java/io/netty/handler/codec/ByteToMessageDecoder.java",
            "previous_commit": "efe40ac17db1a572e4ea43a1a197882c46b419b6",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 2.1591363454618153,
                "p_value": 0.0,
                "effect_size": -0.04979847431160037,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1349798,
                    "after": 1367508
                }
            }
        },
        {
            "commit_message": "Prevent ByteToMessageDecoder from overreading when !isAutoRead (#9252)\n\n\r\nMotivation:\r\n\r\nByteToMessageDecoder only looks at the last channelRead() in the batch\r\nof channelRead()-s when determining whether or not it should call\r\nChannelHandlerContext#read() to consume more data when !isAutoRead. This\r\nwill lead to read() calls issued unnecessaily and unprompted if the very\r\nlast channelRead() didn't result in at least one decoded message, even\r\nif there have been messages decoded from other channelRead()-s in the\r\ncurrent batch.\r\n\r\nModifications:\r\n\r\nTrack decode outcomes for the entire batch of channelRead() calls and\r\nonly issue a read in BTMD if the entire batch of channelRead() calls\r\nyielded no complete messages.\r\n\r\nResult:\r\n\r\nByteToMessageDecoder will no longer overread when the very last read\r\nyielded no message, but the batch of reads did.\r\n",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "public void io.netty.handler.codec.ByteToMessageDecoder.channelReadComplete(io.netty.channel.ChannelHandlerContext) throws java.lang.Exception",
            "method_name_cc": "public void io.netty.handler.codec.ByteToMessageDecoder.channelReadComplete(ChannelHandlerContext ctx)",
            "file": "codec/src/main/java/io/netty/handler/codec/ByteToMessageDecoder.java",
            "previous_method_cc": "public void io.netty.handler.codec.ByteToMessageDecoder.channelReadComplete(ChannelHandlerContext ctx)",
            "previous_method_pd": "public void io.netty.handler.codec.ByteToMessageDecoder.channelReadComplete(io.netty.channel.ChannelHandlerContext) throws java.lang.Exception",
            "previous_file": "codec/src/main/java/io/netty/handler/codec/ByteToMessageDecoder.java",
            "previous_commit": "efe40ac17db1a572e4ea43a1a197882c46b419b6",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 1.6304347826086956,
                "p_value": 0.0,
                "effect_size": -0.08417373773647725,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1280499,
                    "after": 1282462
                }
            }
        }
    ],
    "128403b492d8490d9fc770b7a2dad669433b2790": [
        {
            "commit_message": "Introduce ByteBuf.maxFastWritableBytes() method (#9086)\n\n\r\nMotivation\r\n\r\nByteBuf capacity is automatically increased as needed up to maxCapacity\r\nwhen writing beyond the buffer's current capacity. However there's no\r\nway to tell in general whether such an increase will result in a\r\nrelatively costly internal buffer re-allocation.\r\n\r\nFor unpooled buffers it always does, in pooled cases it depends on the\r\nsize of the associated chunk of allocated memory, which I don't think is\r\ncurrently exposed in any way.\r\n\r\nIt would sometimes be useful to know where this limit is when making\r\nexternal decisions about whether to reuse or preemptively reallocate.\r\n\r\nIt would also be advantageous to take this limit into account when\r\nauto-increasing the capacity during writes, to defer such reallocation\r\nuntil really necessary.\r\n\r\nModifications\r\n\r\nIntroduce new AbstractByteBuf.maxFastWritableBytes() method which will\r\nreturn a value >= writableBytes() and <= maxWritableBytes().\r\n\r\nMake use of the new method in the sizing decision made by the\r\nAbstractByteBuf.ensureWritable(...) methods.\r\n\r\nResult\r\n\r\nLess reallocation/copying.",
            "benchmark": "io.netty.handler.codec.http.WriteBytesVsShortOrMediumBenchmark.byteArray2",
            "method_name_pd": "final void io.netty.buffer.AbstractByteBuf.ensureWritable0(int)",
            "method_name_cc": "final void io.netty.buffer.AbstractByteBuf.ensureWritable0(int minWritableBytes)",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractByteBuf.java",
            "previous_method_cc": "final void io.netty.buffer.AbstractByteBuf.ensureWritable0(int minWritableBytes)",
            "previous_method_pd": "final void io.netty.buffer.AbstractByteBuf.ensureWritable0(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractByteBuf.java",
            "previous_commit": "3eff1dbc1b23e44d4d60473712d93e7be188b170",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -31.548311990686845,
                "p_value": 0.0,
                "effect_size": 0.2606919107571557,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 283350,
                    "after": 255060
                }
            }
        }
    ],
    "d0bcf44445f8692bae6d5a0868f6d3fbe39daf8d": [
        {
            "commit_message": "Fix memory release failure when \"maxNumElems == 1\" of PoolSubpage (#10988)\n\nMotivation:\r\n\r\nwhen customer need large of 'byteBuf.capacity' in [7168, 8192], the size of 'chunk.subpages' may be inflated when large of byteBuf be released, not consistent with other 'byteBuf.capacity'\r\n\r\nModification:\r\n\r\nwhen maxNumElems == 1 need consider remove from pool\r\n\r\nResult:\r\n\r\nFixes #10896. \r\n\r\nCo-authored-by: zxingy <zxingy@servyou.com.cn>",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "boolean io.netty.buffer.PoolSubpage.free(io.netty.buffer.PoolSubpage,int)",
            "method_name_cc": "boolean io.netty.buffer.PoolSubpage<T>.free(PoolSubpage<T> head, int bitmapIdx)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolSubpage.java",
            "previous_method_cc": "boolean io.netty.buffer.PoolSubpage<T>.free(PoolSubpage<T> head, int bitmapIdx)",
            "previous_method_pd": "boolean io.netty.buffer.PoolSubpage.free(io.netty.buffer.PoolSubpage,int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolSubpage.java",
            "previous_commit": "5460ae7d54e7c523c7bba701d02860fa5593a297",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -10.555094748931284,
                "p_value": 0.5817759725502964,
                "effect_size": 0.07415107415107415,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 37,
                    "after": 39
                }
            }
        }
    ],
    "c0674cff29ae017e9fd144b6728ac0521874e883": [
        {
            "commit_message": "Fix infinite loop (#10855)\n\nMotivation:\r\n\r\nTo fix the infinite loop parsing a multipart body.\r\n\r\nModifications:\r\n\r\nModified the loop to use the correct variable.\r\n\r\nResult:\r\n\r\nMultipart bodies will be parsed correctly again.",
            "benchmark": "io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoderBenchmark.multipartRequestDecoderHighSimpleLevel",
            "method_name_pd": "private static int io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoder.findDelimiter(io.netty.buffer.ByteBuf,java.lang.String,int)",
            "method_name_cc": "private static int io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoder.findDelimiter(ByteBuf undecodedChunk, String delimiter, int offset)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/multipart/HttpPostMultipartRequestDecoder.java",
            "previous_method_cc": "private static int io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoder.findDelimiter(ByteBuf undecodedChunk, String delimiter, int offset)",
            "previous_method_pd": "private static int io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoder.findDelimiter(io.netty.buffer.ByteBuf,java.lang.String,int)",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/multipart/HttpPostMultipartRequestDecoder.java",
            "previous_commit": "b4479353e2485aa2f0293bc748920560c0ddeaf2",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.27408812987560616,
                "p_value": 8.899728299353944e-196,
                "effect_size": -0.044762589217913554,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 296409,
                    "after": 296495
                }
            }
        }
    ],
    "c8c45cfa4c9632578a772ebcad1edfae431b1011": [
        {
            "commit_message": "O(1) buffer next capacity computation (#11641)\n\nMotivation:\r\n\r\nEnlarging buffers approaching 4 MiB size requires n iterations\r\n\r\nModification:\r\n\r\nUse a single instruction to compute the next buffer capacity\r\n\r\nResult:\r\n\r\nFaster/Simpler calculateNewCapacity",
            "benchmark": "io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoderBenchmark.multipartRequestDecoderHighSimpleLevel",
            "method_name_pd": "public int io.netty.buffer.AbstractByteBufAllocator.calculateNewCapacity(int,int)",
            "method_name_cc": "public int io.netty.buffer.AbstractByteBufAllocator.calculateNewCapacity(int minNewCapacity, int maxCapacity)",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java",
            "previous_method_cc": "public int io.netty.buffer.AbstractByteBufAllocator.calculateNewCapacity(int minNewCapacity, int maxCapacity)",
            "previous_method_pd": "public int io.netty.buffer.AbstractByteBufAllocator.calculateNewCapacity(int,int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java",
            "previous_commit": "77cf43cfe9504c91ba8a29b00c05805943db7e46",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 1.0999007608336089,
                "p_value": 0.0,
                "effect_size": -0.07783023611267549,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 217402,
                    "after": 214895
                }
            }
        }
    ],
    "9f242d27e05651a909571f232dd1f5afb1aed20c": [
        {
            "commit_message": "Make CompositeByteBuf throw IllegalStateException when components are missing (#11100)\n\nMotivation:\r\nComponents in a composite buffer can \"go missing\" if the composite is a slice of another composite and the parent has changed its layout.\r\n\r\nModification:\r\nWhere we would previously have thrown a NullPointerException, we now have a null-check for the component, and we instead throw an IllegalStateException with a more descriptive message.\r\n\r\nResult:\r\nIt's now a bit easier to understand what is going on in these situations.\r\n\r\nFixes #10908",
            "benchmark": "io.netty.buffer.CompositeByteBufRandomAccessBenchmark.setGetLong",
            "method_name_pd": "private io.netty.buffer.CompositeByteBuf$Component io.netty.buffer.CompositeByteBuf.findIt(int)",
            "method_name_cc": "private Component io.netty.buffer.CompositeByteBuf.findIt(int offset)",
            "file": "buffer/src/main/java/io/netty/buffer/CompositeByteBuf.java",
            "previous_method_cc": "private Component io.netty.buffer.CompositeByteBuf.findIt(int offset)",
            "previous_method_pd": "private io.netty.buffer.CompositeByteBuf$Component io.netty.buffer.CompositeByteBuf.findIt(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/CompositeByteBuf.java",
            "previous_commit": "bd62a9d6ffd9941d9e399cbbd73a10f06e38f217",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -15.884476534296029,
                "p_value": 0.0,
                "effect_size": 0.10246925304268076,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1386814,
                    "after": 1383804
                }
            }
        }
    ],
    "f191f89a827d4a4151faffb38d215385e91fa3d3": [
        {
            "commit_message": "Track independent refCnt in MixedAttribute and MixedFileUpload (#12650)\n\nMotivation:\r\n\r\nBefore this patch, MixedAttribute and MixedFileUpload delegated reference counting to their underlying memory or file representation. When the representation changes from memory to disk because the memory size limit was exceeded, the reference count of the old representation is not transferred, so the reference attribute resets to 1. This may leak the memory of the old representation, and may lead to exceptions when users try to release the mixed data.\r\n\r\nModification:\r\n\r\nIntroduce a new AbstractMixedHttpData class, analogous to the existing abstract classes for disk and memory data. This new class does its own reference counting, and unifies the swapping mechanism for attributes and file uploads.\r\n\r\nThe change is fairly big, but it's mostly copied from the old implementations. Makes it a bit annoying to review though, so I might have missed a bug.\r\n\r\nI tried inheriting from AbstractHttpData, but it didn't really reduce the code size much, and makes some code less clear because it leads to two copies of the name, charset, etc.\r\n\r\nRegarding compatibility, I managed to fix most compat issues reported by revapi. However inheriting from a new class in a non-final class is apparently a breaking change no matter what we do, and additionally AbstractReferenceCounted.setRefCnt is problematic. I think both of these errors are unlikely to affect anyone, and are justifiable. I've added an exclusion to the pom.\r\n\r\nThere is a new test class to test the retain/refCnt behavior. I didn't add it to the HttpDataTest, because the data defined there does not have a size limit we can use to test easily.\r\n\r\nResult:\r\n\r\nMixedAttribute and MixedFileUpload now behave like any other reference counted object.",
            "benchmark": "io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoderBenchmark.multipartRequestDecoderHighSimpleLevel",
            "method_name_pd": "public java.lang.String io.netty.handler.codec.http.multipart.MixedAttribute.getValue() throws java.io.IOException",
            "method_name_cc": "public String io.netty.handler.codec.http.multipart.MixedAttribute.getValue()",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/multipart/MixedAttribute.java",
            "previous_method_cc": "public String io.netty.handler.codec.http.multipart.MixedAttribute.getValue()",
            "previous_method_pd": "public java.lang.String io.netty.handler.codec.http.multipart.MixedAttribute.getValue() throws java.io.IOException",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/multipart/MixedAttribute.java",
            "previous_commit": "c37c637f096e7be3dffd36edee3455c8e90cb1b0",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -3.82685069008783,
                "p_value": 0.0,
                "effect_size": -0.11283242224330033,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 283278,
                    "after": 290217
                }
            }
        }
    ],
    "9ed41db1d731720c3c1019d3db379beaf7603409": [
        {
            "commit_message": "Have (Epoll|KQueue)RecvByteAllocatorHandle extend DelegatingHandle (#9060)\n\nMotivation\r\n\r\nThese implementations delegate most of their methods to an existing Handle and previously extended RecvByteBufAllocator.DelegatingHandle. This was reverted in #6322 with the introduction of ExtendedHandle but it's not clear to me why it needed to be - the code looks a lot cleaner.\r\n\r\nModifications\r\n\r\nHave (Epoll|KQueue)RecvByteAllocatorHandle extend DelegatingHandle again, while still implementing ExtendedHandle.\r\n\r\nResult\r\n\r\nLess code.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading(io.netty.util.UncheckedBooleanSupplier)",
            "method_name_cc": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java",
            "previous_method_cc": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier)",
            "previous_method_pd": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading(io.netty.util.UncheckedBooleanSupplier)",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java",
            "previous_commit": "075cf8c02e005d61f424137d1b786b2ac669998e",
            "performance_diff": -0.0,
            "significance": {}
        },
        {
            "commit_message": "Have (Epoll|KQueue)RecvByteAllocatorHandle extend DelegatingHandle (#9060)\n\nMotivation\r\n\r\nThese implementations delegate most of their methods to an existing Handle and previously extended RecvByteBufAllocator.DelegatingHandle. This was reverted in #6322 with the introduction of ExtendedHandle but it's not clear to me why it needed to be - the code looks a lot cleaner.\r\n\r\nModifications\r\n\r\nHave (Epoll|KQueue)RecvByteAllocatorHandle extend DelegatingHandle again, while still implementing ExtendedHandle.\r\n\r\nResult\r\n\r\nLess code.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading()",
            "method_name_cc": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading()",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java",
            "previous_method_cc": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading()",
            "previous_method_pd": "public final boolean io.netty.channel.epoll.EpollRecvByteAllocatorHandle.continueReading()",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java",
            "previous_commit": "075cf8c02e005d61f424137d1b786b2ac669998e",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "regression",
                "median_change_percentage": 64.70926058865757,
                "p_value": 0.0,
                "effect_size": -0.9482820909006826,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 270217,
                    "after": 275552
                }
            }
        },
        {
            "commit_message": "Have (Epoll|KQueue)RecvByteAllocatorHandle extend DelegatingHandle (#9060)\n\nMotivation\r\n\r\nThese implementations delegate most of their methods to an existing Handle and previously extended RecvByteBufAllocator.DelegatingHandle. This was reverted in #6322 with the introduction of ExtendedHandle but it's not clear to me why it needed to be - the code looks a lot cleaner.\r\n\r\nModifications\r\n\r\nHave (Epoll|KQueue)RecvByteAllocatorHandle extend DelegatingHandle again, while still implementing ExtendedHandle.\r\n\r\nResult\r\n\r\nLess code.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public final io.netty.buffer.ByteBuf io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(io.netty.buffer.ByteBufAllocator)",
            "method_name_cc": "public final ByteBuf io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(ByteBufAllocator alloc)",
            "file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java",
            "previous_method_cc": "public final ByteBuf io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(ByteBufAllocator alloc)",
            "previous_method_pd": "public final io.netty.buffer.ByteBuf io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(io.netty.buffer.ByteBufAllocator)",
            "previous_file": "transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollRecvByteAllocatorHandle.java",
            "previous_commit": "075cf8c02e005d61f424137d1b786b2ac669998e",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.16032648301996794,
                "p_value": 1.992043222687307e-48,
                "effect_size": 0.02253514613426028,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 284399,
                    "after": 277150
                }
            }
        }
    ],
    "19b4adf79c2d82d14e645be0e5f3eca30067bf1b": [
        {
            "commit_message": "Avoid wrapping scheduled Runnables in Callable adapter (#9666)\n\n\r\nMotivation\r\n\r\nCurrently when future tasks are scheduled via schedule(Runnable, ...)\r\nmethods, the supplied Runnable is wrapped in a newly allocated Callable\r\nadapter prior to being wrapped in a ScheduledFutureTask.\r\n\r\nThis can be avoided which saves an object allocation per scheduled task.\r\n\r\nModifications\r\n\r\nChange the Callable task field of ScheduledFutureTask to be of type\r\nObject so that it can hold/run Runnables directly in addition to\r\nCallables.\r\n\r\nAn \"adapter\" is still used in the case a Runnable is scheduled with an\r\nexplicit constant non-null completion value, assumed to be rare.\r\n\r\nResult\r\n\r\nLess garbage\r\n",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.executeSingle",
            "method_name_pd": "public void io.netty.util.concurrent.PromiseTask.run()",
            "method_name_cc": "public void io.netty.util.concurrent.PromiseTask<V>.run()",
            "file": "common/src/main/java/io/netty/util/concurrent/PromiseTask.java",
            "previous_method_cc": "public void io.netty.util.concurrent.PromiseTask<V>.run()",
            "previous_method_pd": "public void io.netty.util.concurrent.PromiseTask.run()",
            "previous_file": "common/src/main/java/io/netty/util/concurrent/PromiseTask.java",
            "previous_commit": "bbc34d0eda38efb4a6364561e9ac1d2319682694",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.5396194262993468,
                "p_value": 8.212114325311233e-85,
                "effect_size": 0.030722706092406328,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 263589,
                    "after": 274597
                }
            }
        }
    ],
    "2af769f6dc76e3aad88a52c345689d739a9130a2": [
        {
            "commit_message": "Subsequence versions of ByteBufUtil#writeUtf8(...) methods (#9224)\n\nMotivation\r\n\r\nIt would be useful to be able to write UTF-8 encoded subsequence of\r\nCharSequence characters to a ByteBuf without needing to create a\r\ntemporary object via CharSequence#subSequence().\r\n\r\nModification\r\n\r\nAdd overloads of ByteBufUtil writeUtf8, reserveAndWriteUtf8 and\r\nutf8Bytes methods which take explicit subsequence bounds.\r\n\r\nResult\r\n\r\nMore efficient writing of substrings to byte buffers possible\r\n",
            "benchmark": "io.netty.microbench.buffer.ByteBufUtilBenchmark.writeUtf8Wrapped",
            "method_name_pd": "public static int io.netty.buffer.ByteBufUtil.writeUtf8(io.netty.buffer.ByteBuf,java.lang.CharSequence)",
            "method_name_cc": "public static int io.netty.buffer.ByteBufUtil.writeUtf8(ByteBuf buf, CharSequence seq)",
            "file": "buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
            "previous_method_cc": "public static int io.netty.buffer.ByteBufUtil.writeUtf8(ByteBuf buf, CharSequence seq)",
            "previous_method_pd": "public static int io.netty.buffer.ByteBufUtil.writeUtf8(io.netty.buffer.ByteBuf,java.lang.CharSequence)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
            "previous_commit": "9dd1aab482fedc627b663cde10ae75dbab66edf9",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -58.93298110607018,
                "p_value": 0.0,
                "effect_size": 0.7367362918435267,
                "effect_size_interpretation": "large",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 292720,
                    "after": 277855
                }
            }
        }
    ],
    "fedf3ccecb80ddccd05da2d02e76d669fe2c219c": [
        {
            "commit_message": "Harden ref-counting concurrency semantics (#8583)\n\n\r\nMotivation\r\n\r\n#8563 highlighted race conditions introduced by the prior optimistic\r\nupdate optimization in 83a19d565064ee36998eb94f946e5a4264001065. These\r\nwere known at the time but considered acceptable given the perf\r\nbenefit in high contention scenarios.\r\n\r\nThis PR proposes a modified approach which provides roughly half the\r\ngains but stronger concurrency semantics. Race conditions still exist\r\nbut their scope is narrowed to much less likely cases (releases\r\ncoinciding with retain overflow), and even in those\r\ncases certain guarantees are still assured. Once release() returns true,\r\nall subsequent release/retains are guaranteed to throw, and in\r\nparticular deallocate will be called at most once.\r\n\r\nModifications\r\n\r\n- Use even numbers internally (including -ve) for live refcounts\r\n- \"Final\" release changes to odd number (equivalent to refcount 0)\r\n- Retain still uses faster getAndAdd, release uses CAS loop\r\n- First CAS attempt uses non-volatile read\r\n- Thread.yield() after a failed CAS provides a net gain\r\n\r\nResult\r\n\r\nMore (though not completely) robust concurrency semantics for ref\r\ncounting; increased latency under high contention, but still roughly\r\ntwice as fast as the original logic. Bench results to follow\r\n",
            "benchmark": "io.netty.microbench.redis.RedisEncoderBenchmark.writeArray",
            "method_name_pd": "private boolean io.netty.util.AbstractReferenceCounted.release0(int)",
            "method_name_cc": "private boolean io.netty.buffer.AbstractReferenceCountedByteBuf.release0(int decrement)",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_method_cc": "private boolean io.netty.buffer.AbstractReferenceCountedByteBuf.release0(int decrement)",
            "previous_method_pd": "private boolean io.netty.util.AbstractReferenceCounted.release0(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_commit": "057c19f92ac8b5f9ee34b9e6d813a65ee4707c15",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.16330974414806748,
                "p_value": 1.1700597990762209e-271,
                "effect_size": 0.016916985750752248,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 2880577,
                    "after": 2897148
                }
            }
        },
        {
            "commit_message": "Harden ref-counting concurrency semantics (#8583)\n\n\r\nMotivation\r\n\r\n#8563 highlighted race conditions introduced by the prior optimistic\r\nupdate optimization in 83a19d565064ee36998eb94f946e5a4264001065. These\r\nwere known at the time but considered acceptable given the perf\r\nbenefit in high contention scenarios.\r\n\r\nThis PR proposes a modified approach which provides roughly half the\r\ngains but stronger concurrency semantics. Race conditions still exist\r\nbut their scope is narrowed to much less likely cases (releases\r\ncoinciding with retain overflow), and even in those\r\ncases certain guarantees are still assured. Once release() returns true,\r\nall subsequent release/retains are guaranteed to throw, and in\r\nparticular deallocate will be called at most once.\r\n\r\nModifications\r\n\r\n- Use even numbers internally (including -ve) for live refcounts\r\n- \"Final\" release changes to odd number (equivalent to refcount 0)\r\n- Retain still uses faster getAndAdd, release uses CAS loop\r\n- First CAS attempt uses non-volatile read\r\n- Thread.yield() after a failed CAS provides a net gain\r\n\r\nResult\r\n\r\nMore (though not completely) robust concurrency semantics for ref\r\ncounting; increased latency under high contention, but still roughly\r\ntwice as fast as the original logic. Bench results to follow\r\n",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "int io.netty.buffer.AbstractReferenceCountedByteBuf.internalRefCnt()",
            "method_name_cc": "int io.netty.buffer.AbstractReferenceCountedByteBuf.internalRefCnt()",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_method_cc": "int io.netty.buffer.AbstractReferenceCountedByteBuf.internalRefCnt()",
            "previous_method_pd": "int io.netty.buffer.AbstractReferenceCountedByteBuf.internalRefCnt()",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_commit": "057c19f92ac8b5f9ee34b9e6d813a65ee4707c15",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.08869179600886917,
                "p_value": 0.0,
                "effect_size": -0.029231103840843885,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1320564,
                    "after": 1318941
                }
            }
        },
        {
            "commit_message": "Harden ref-counting concurrency semantics (#8583)\n\n\r\nMotivation\r\n\r\n#8563 highlighted race conditions introduced by the prior optimistic\r\nupdate optimization in 83a19d565064ee36998eb94f946e5a4264001065. These\r\nwere known at the time but considered acceptable given the perf\r\nbenefit in high contention scenarios.\r\n\r\nThis PR proposes a modified approach which provides roughly half the\r\ngains but stronger concurrency semantics. Race conditions still exist\r\nbut their scope is narrowed to much less likely cases (releases\r\ncoinciding with retain overflow), and even in those\r\ncases certain guarantees are still assured. Once release() returns true,\r\nall subsequent release/retains are guaranteed to throw, and in\r\nparticular deallocate will be called at most once.\r\n\r\nModifications\r\n\r\n- Use even numbers internally (including -ve) for live refcounts\r\n- \"Final\" release changes to odd number (equivalent to refcount 0)\r\n- Retain still uses faster getAndAdd, release uses CAS loop\r\n- First CAS attempt uses non-volatile read\r\n- Thread.yield() after a failed CAS provides a net gain\r\n\r\nResult\r\n\r\nMore (though not completely) robust concurrency semantics for ref\r\ncounting; increased latency under high contention, but still roughly\r\ntwice as fast as the original logic. Bench results to follow\r\n",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "public int io.netty.buffer.AbstractReferenceCountedByteBuf.refCnt()",
            "method_name_cc": "public int io.netty.buffer.AbstractReferenceCountedByteBuf.refCnt()",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_method_cc": "public int io.netty.buffer.AbstractReferenceCountedByteBuf.refCnt()",
            "previous_method_pd": "public int io.netty.buffer.AbstractReferenceCountedByteBuf.refCnt()",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_commit": "057c19f92ac8b5f9ee34b9e6d813a65ee4707c15",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.8189262966333031,
                "p_value": 0.0,
                "effect_size": -0.05665652877025919,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1281218,
                    "after": 1275693
                }
            }
        },
        {
            "commit_message": "Harden ref-counting concurrency semantics (#8583)\n\n\r\nMotivation\r\n\r\n#8563 highlighted race conditions introduced by the prior optimistic\r\nupdate optimization in 83a19d565064ee36998eb94f946e5a4264001065. These\r\nwere known at the time but considered acceptable given the perf\r\nbenefit in high contention scenarios.\r\n\r\nThis PR proposes a modified approach which provides roughly half the\r\ngains but stronger concurrency semantics. Race conditions still exist\r\nbut their scope is narrowed to much less likely cases (releases\r\ncoinciding with retain overflow), and even in those\r\ncases certain guarantees are still assured. Once release() returns true,\r\nall subsequent release/retains are guaranteed to throw, and in\r\nparticular deallocate will be called at most once.\r\n\r\nModifications\r\n\r\n- Use even numbers internally (including -ve) for live refcounts\r\n- \"Final\" release changes to odd number (equivalent to refcount 0)\r\n- Retain still uses faster getAndAdd, release uses CAS loop\r\n- First CAS attempt uses non-volatile read\r\n- Thread.yield() after a failed CAS provides a net gain\r\n\r\nResult\r\n\r\nMore (though not completely) robust concurrency semantics for ref\r\ncounting; increased latency under high contention, but still roughly\r\ntwice as fast as the original logic. Bench results to follow\r\n",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "private boolean io.netty.buffer.AbstractReferenceCountedByteBuf.release0(int)",
            "method_name_cc": "private boolean io.netty.buffer.AbstractReferenceCountedByteBuf.release0(int decrement)",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_method_cc": "private boolean io.netty.buffer.AbstractReferenceCountedByteBuf.release0(int decrement)",
            "previous_method_pd": "private boolean io.netty.util.AbstractReferenceCounted.release0(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java",
            "previous_commit": "057c19f92ac8b5f9ee34b9e6d813a65ee4707c15",
            "performance_diff": 0.5918188577378807,
            "significance": {}
        }
    ],
    "948d4a9ec58aef092c84eb76e672fd06e81cc13c": [
        {
            "commit_message": "Minimize memory footprint for AbstractChannelHandlerContext for handlers that execute in the EventExecutor. (#8786)\n\nMotivation:\r\n\r\nWe cache the Runnable for some tasks to reduce GC pressure in 4 different fields. This gives overhead in terms of memory usage in all cases, even if we always execute in the EventExecutor (which is the case most of the times).\r\n\r\nModifications:\r\n\r\nMove the 4 fields to another class and only have one reference to this in AbstractChannelHandlerContext. This gives a small overhead in the case of execution that is done outside of the EventExecutor but reduce memory footprint in the more likily execution case.\r\n\r\nResult:\r\n\r\nLess memory used per AbstractChannelHandlerContext in most cases.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "method_name_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "previous_method_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.read()",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "cd3254df88b60476dc04b39915d3d70c200eb6f4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -3.9433617539585875,
                "p_value": 0.0,
                "effect_size": 0.0959994464449429,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 295076,
                    "after": 294793
                }
            }
        },
        {
            "commit_message": "Minimize memory footprint for AbstractChannelHandlerContext for handlers that execute in the EventExecutor. (#8786)\n\nMotivation:\r\n\r\nWe cache the Runnable for some tasks to reduce GC pressure in 4 different fields. This gives overhead in terms of memory usage in all cases, even if we always execute in the EventExecutor (which is the case most of the times).\r\n\r\nModifications:\r\n\r\nMove the 4 fields to another class and only have one reference to this in AbstractChannelHandlerContext. This gives a small overhead in the case of execution that is done outside of the EventExecutor but reduce memory footprint in the more likily execution case.\r\n\r\nResult:\r\n\r\nLess memory used per AbstractChannelHandlerContext in most cases.",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "method_name_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "public ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "previous_method_pd": "public io.netty.channel.ChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.flush()",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "cd3254df88b60476dc04b39915d3d70c200eb6f4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.6142677649029736,
                "p_value": 0.0,
                "effect_size": -0.06872700326850313,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 217268,
                    "after": 211850
                }
            }
        }
    ],
    "4db38b4e0c734b9cdaf0591dd0c5b3f4d4f11ea4": [
        {
            "commit_message": "Don't zero non-readable buffer regions when capacity is decreased (#9427)\n\nMotivation\r\n\r\n#1802 fixed ByteBuf implementations to ensure that the whole buffer\r\nregion is preserved when capacity is increased, not just the readable\r\npart. The behaviour is still different however when the capacity is\r\n_decreased_ - data outside the currently-readable region is zeroed.\r\n\r\nModifications\r\n\r\nUpdate ByteBuf capacity(int) implementations to also copy the whole\r\nbuffer region when the new capacity is less than the current capacity.\r\n\r\nResult\r\n\r\nConsistent behaviour of ByteBuf#capacity(int) regardless of whether the\r\nnew capacity is greater than or less than the current capacity.",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "void io.netty.buffer.PoolArena.reallocate(io.netty.buffer.PooledByteBuf,int,boolean)",
            "method_name_cc": "void io.netty.buffer.PoolArena<T>.reallocate(PooledByteBuf<T> buf, int newCapacity, boolean freeOldMemory)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolArena.java",
            "previous_method_cc": "void io.netty.buffer.PoolArena<T>.reallocate(PooledByteBuf<T> buf, int newCapacity, boolean freeOldMemory)",
            "previous_method_pd": "void io.netty.buffer.PoolArena.reallocate(io.netty.buffer.PooledByteBuf,int,boolean)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolArena.java",
            "previous_commit": "9ec3411c91bdc50e78f3d50b393ab815d2be0f92",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.7742873763816174,
                "p_value": 0.0,
                "effect_size": 0.1408327118809804,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1153913,
                    "after": 1153177
                }
            }
        },
        {
            "commit_message": "Don't zero non-readable buffer regions when capacity is decreased (#9427)\n\nMotivation\r\n\r\n#1802 fixed ByteBuf implementations to ensure that the whole buffer\r\nregion is preserved when capacity is increased, not just the readable\r\npart. The behaviour is still different however when the capacity is\r\n_decreased_ - data outside the currently-readable region is zeroed.\r\n\r\nModifications\r\n\r\nUpdate ByteBuf capacity(int) implementations to also copy the whole\r\nbuffer region when the new capacity is less than the current capacity.\r\n\r\nResult\r\n\r\nConsistent behaviour of ByteBuf#capacity(int) regardless of whether the\r\nnew capacity is greater than or less than the current capacity.",
            "benchmark": "io.netty.buffer.ByteBufNoCleanerChangeCapacityBenchmark.capacityChange",
            "method_name_pd": "public io.netty.buffer.ByteBuf io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf.capacity(int)",
            "method_name_cc": "public ByteBuf io.netty.buffer.UnpooledDirectByteBuf.capacity(int newCapacity)",
            "file": "buffer/src/main/java/io/netty/buffer/UnpooledDirectByteBuf.java",
            "previous_method_cc": "public ByteBuf io.netty.buffer.UnpooledDirectByteBuf.capacity(int newCapacity)",
            "previous_method_pd": "public io.netty.buffer.ByteBuf io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf.capacity(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/UnpooledDirectByteBuf.java",
            "previous_commit": "9ec3411c91bdc50e78f3d50b393ab815d2be0f92",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -7.8002871271335135,
                "p_value": 0.0,
                "effect_size": 0.059577383085040014,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 274359,
                    "after": 271185
                }
            }
        }
    ],
    "2dc686ded17d8123118921ac6d36aea30cdce267": [
        {
            "commit_message": "Prefer direct io buffers if direct buffers pooled (#9167)\n\nMotivation\r\n\r\nDirect buffers are normally preferred when interfacing with raw\r\nsockets. Currently netty will only return direct io buffers (for reading\r\nfrom a channel) when a platform has unsafe. However, this is\r\ninconsistent with the write-side (filterOutboundMessage) where a direct\r\nbyte buffer will be returned if pooling is enabled. This means that\r\nenvironments without unsafe (and no manual netty configurations) end up\r\nwith many pooled heap byte buffers for reading, many pooled direct byte\r\nbuffers for writing, and jdk pooled byte buffers (for reading).\r\n\r\nModifications\r\n\r\nThis commit modifies the AbstractByteBufAllocator to return a direct\r\nbyte buffer for io handling when the platform has unsafe or direct byte\r\nbuffers are pooled.\r\n\r\nResult:\r\n\r\nUse direct buffers when direct buffers are pooled for IO.",
            "benchmark": "io.netty.microbench.redis.RedisEncoderBenchmark.writeArray",
            "method_name_pd": "public io.netty.buffer.ByteBuf io.netty.buffer.AbstractByteBufAllocator.ioBuffer(int)",
            "method_name_cc": "public ByteBuf io.netty.buffer.AbstractByteBufAllocator.ioBuffer(int initialCapacity)",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java",
            "previous_method_cc": "public ByteBuf io.netty.buffer.AbstractByteBufAllocator.ioBuffer(int initialCapacity)",
            "previous_method_pd": "public io.netty.buffer.ByteBuf io.netty.buffer.AbstractByteBufAllocator.ioBuffer(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java",
            "previous_commit": "afdc77f9d3f6ecef9d0f73048a232de6d74d8d07",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -1.6495601173020527,
                "p_value": 2.0282941020831722e-61,
                "effect_size": 0.007491144468770281,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3237674,
                    "after": 3259057
                }
            }
        }
    ],
    "9563d2bd61cabc4558246a6b6986d8769e32829e": [
        {
            "commit_message": "Cleanup PoolChunk / PoolSubpage and add a few more asserts (#10690)\n\nMotivation:\r\n\r\nAs the PooledByteBufAllocator is a critical part of netty we should ensure it works as expected.\r\n\r\nModifications:\r\n\r\n- Add a few more asserts to ensure we not see any corrupted state\r\n- Null out slot in the subpage array once the subpage was freed and removed from the pool\r\n- Merge methods into constructor as it was only called from the constructor anyway.\r\n\r\nResult:\r\n\r\nCode cleanup",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "private long io.netty.buffer.PoolChunk.allocateSubpage(int)",
            "method_name_cc": "private long io.netty.buffer.PoolChunk<T>.allocateSubpage(int sizeIdx)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "private long io.netty.buffer.PoolChunk<T>.allocateSubpage(int sizeIdx)",
            "previous_method_pd": "private long io.netty.buffer.PoolChunk.allocateSubpage(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "0ed788c15e688dd052e51a5934e881a7786b94a2",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 9.022480077905334,
                "p_value": 0.7006448435423338,
                "effect_size": -0.048701298701298704,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 42,
                    "after": 44
                }
            }
        },
        {
            "commit_message": "Cleanup PoolChunk / PoolSubpage and add a few more asserts (#10690)\n\nMotivation:\r\n\r\nAs the PooledByteBufAllocator is a critical part of netty we should ensure it works as expected.\r\n\r\nModifications:\r\n\r\n- Add a few more asserts to ensure we not see any corrupted state\r\n- Null out slot in the subpage array once the subpage was freed and removed from the pool\r\n- Merge methods into constructor as it was only called from the constructor anyway.\r\n\r\nResult:\r\n\r\nCode cleanup",
            "benchmark": "io.netty.microbench.channel.epoll.EpollSocketChannelBenchmark.pingPong",
            "method_name_pd": "void io.netty.buffer.PoolChunk.free(long,int,java.nio.ByteBuffer)",
            "method_name_cc": "void io.netty.buffer.PoolChunk<T>.free(long handle, int normCapacity, ByteBuffer nioBuffer)",
            "file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_method_cc": "void io.netty.buffer.PoolChunk<T>.free(long handle, int normCapacity, ByteBuffer nioBuffer)",
            "previous_method_pd": "void io.netty.buffer.PoolChunk.free(long,int,java.nio.ByteBuffer)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/PoolChunk.java",
            "previous_commit": "0ed788c15e688dd052e51a5934e881a7786b94a2",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 7.163990087011583,
                "p_value": 0.2916396327772809,
                "effect_size": -0.14035087719298245,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 0,
                "sample_size": {
                    "before": 38,
                    "after": 39
                }
            }
        }
    ],
    "7fce06a0d1f76865b1494fde99697c31a8a1f92f": [
        {
            "commit_message": "Preserve order when using alternate event loops (#10069)\n\nMotivation:\r\n\r\nWhen the HttpContentCompressor is put on an alternate EventExecutor, the order of events should be\r\npreserved so that the compressed content is correctly created.\r\n\r\nModifications:\r\n- checking that the executor in the ChannelHandlerContext is the same executor as the current executor when evaluating if the handler should be skipped.\r\n- Add unit test\r\n\r\nResult:\r\n\r\nFixes https://github.com/netty/netty/issues/10067\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>\r\n",
            "benchmark": "io.netty.microbench.channel.DefaultChannelPipelineBenchmark.propagateEvent",
            "method_name_pd": "private io.netty.channel.AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextInbound(int)",
            "method_name_cc": "private AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextInbound(int mask)",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "private AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextInbound(int mask)",
            "previous_method_pd": "private io.netty.channel.AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextInbound(int)",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "04532220152a69a04064537daffd9e57953b81c0",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -2.0146520146520146,
                "p_value": 3.268019018144959e-216,
                "effect_size": 0.051288064727403535,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 236703,
                    "after": 264070
                }
            }
        },
        {
            "commit_message": "Preserve order when using alternate event loops (#10069)\n\nMotivation:\r\n\r\nWhen the HttpContentCompressor is put on an alternate EventExecutor, the order of events should be\r\npreserved so that the compressed content is correctly created.\r\n\r\nModifications:\r\n- checking that the executor in the ChannelHandlerContext is the same executor as the current executor when evaluating if the handler should be skipped.\r\n- Add unit test\r\n\r\nResult:\r\n\r\nFixes https://github.com/netty/netty/issues/10067\r\n\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>\r\n",
            "benchmark": "io.netty.microbench.channel.DefaultChannelPipelineBenchmark.propagateEvent",
            "method_name_pd": "private io.netty.channel.AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextOutbound(int)",
            "method_name_cc": "private AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextOutbound(int mask)",
            "file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_method_cc": "private AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextOutbound(int mask)",
            "previous_method_pd": "private io.netty.channel.AbstractChannelHandlerContext io.netty.channel.AbstractChannelHandlerContext.findContextOutbound(int)",
            "previous_file": "transport/src/main/java/io/netty/channel/AbstractChannelHandlerContext.java",
            "previous_commit": "04532220152a69a04064537daffd9e57953b81c0",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -3.6453645364536458,
                "p_value": 0.0,
                "effect_size": 0.12862535153203292,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 242650,
                    "after": 264154
                }
            }
        }
    ],
    "707c95e80d60cd83336b5355474676dab7b26e3a": [
        {
            "commit_message": "Use ByteProcessor in HpackHuffmanDecoder to reduce bound-checks and r\u2026 (#9317)\n\n\r\nMotivation:\r\n\r\nff0045e3e10684425a26f5b6cb02223fb0444141 changed HpackHuffmanDecoder to use a lookup-table which greatly improved performance. We can squeeze out another 3% win by using an ByteProcessor which will reduce the number of bound-checks / reference-count-checks needed by processing byte-by-byte.\r\n\r\nModifications:\r\n\r\nImplement logic with ByteProcessor\r\n\r\nResult:\r\n\r\nAnother ~3% perf improvement which shows up when using h2load to simulate load.\r\n\r\n`h2load -c 100 -m 100 --duration 60 --warm-up-time 10 http://127.0.0.1:8080`\r\n\r\nBefore:\r\n\r\n```\r\nfinished in 70.02s, 620051.67 req/s, 20.70MB/s\r\nrequests: 37203100 total, 37203100 started, 37203100 done, 37203100 succeeded, 0 failed, 0 errored, 0 timeout\r\nstatus codes: 37203100 2xx, 0 3xx, 0 4xx, 0 5xx\r\ntraffic: 1.21GB (1302108500) total, 41.84MB (43872600) headers (space savings 90.00%), 460.24MB (482598600) data\r\n                     min         max         mean         sd        +/- sd\r\ntime for request:      404us     24.52ms     15.93ms      1.45ms    87.90%\r\ntime for connect:        0us         0us         0us         0us     0.00%\r\ntime to 1st byte:        0us         0us         0us         0us     0.00%\r\nreq/s           :    6186.64     6211.60     6199.00        5.18    65.00%\r\n```\r\n\r\nWith this change:\r\n\r\n```\r\nfinished in 70.02s, 642103.33 req/s, 21.43MB/s\r\nrequests: 38526200 total, 38526200 started, 38526200 done, 38526200 succeeded, 0 failed, 0 errored, 0 timeout\r\nstatus codes: 38526200 2xx, 0 3xx, 0 4xx, 0 5xx\r\ntraffic: 1.26GB (1348417000) total, 42.39MB (44444900) headers (space savings 90.00%), 466.25MB (488893900) data\r\n                     min         max         mean         sd        +/- sd\r\ntime for request:      370us     24.89ms     15.52ms      1.35ms    88.02%\r\ntime for connect:        0us         0us         0us         0us     0.00%\r\ntime to 1st byte:        0us         0us         0us         0us     0.00%\r\nreq/s           :    6407.06     6435.19     6419.74        5.62    67.00%\r\n```",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private java.lang.CharSequence io.netty.handler.codec.http2.HpackDecoder.readStringLiteral(io.netty.buffer.ByteBuf,int,boolean) throws io.netty.handler.codec.http2.Http2Exception",
            "method_name_cc": "private CharSequence io.netty.handler.codec.http2.HpackDecoder.readStringLiteral(ByteBuf in, int length, boolean huffmanEncoded)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackDecoder.java",
            "previous_method_cc": "private CharSequence io.netty.handler.codec.http2.HpackDecoder.readStringLiteral(ByteBuf in, int length, boolean huffmanEncoded)",
            "previous_method_pd": "private java.lang.CharSequence io.netty.handler.codec.http2.HpackDecoder.readStringLiteral(io.netty.buffer.ByteBuf,int,boolean) throws io.netty.handler.codec.http2.Http2Exception",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackDecoder.java",
            "previous_commit": "16b98d370f77b3ff389cbcdffee3b63779f0587a",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.9857612267250823,
                "p_value": 4.399454339982899e-257,
                "effect_size": -0.019283921801564994,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 2100666,
                    "after": 2105275
                }
            }
        }
    ],
    "86603872776e3ff5a60dea3c104358e486eed588": [
        {
            "commit_message": "Allow attaching additional metadata to ResourceLeakTrackers on creation (#12091)\n\n\r\nMotivation:\r\nAttaching metadata to the creation record of a ResourceLeakTracker allows implementations to give more context information about where the leak originated from, such as the currently running test case, or, for fuzzing tests, the input that caused the leak.\r\n\r\nModification:\r\nAdd a protected method getInitialHint to ResourceLeakDetector that is called to populate the hint of the first TraceRecord of a leak. The method returns null by default, keeping the old behavior.\r\n\r\nResult:\r\nSubclasses can override the new method to supply metadata that is then interpreted the same way as a hint passed to ResourceLeakTracker.track, and attached to the \"Created at:\" record.\r\n\r\nCo-authored-by: Chris Vest <christianvest_hansen@apple.com>",
            "benchmark": "io.netty.handler.codec.http.multipart.HttpPostMultipartRequestDecoderBenchmark.multipartRequestDecoderBigParanoidLevel",
            "method_name_pd": "private void io.netty.util.ResourceLeakDetector.reportLeak()",
            "method_name_cc": "private void io.netty.util.ResourceLeakDetector<T>.reportLeak()",
            "file": "common/src/main/java/io/netty/util/ResourceLeakDetector.java",
            "previous_method_cc": "private void io.netty.util.ResourceLeakDetector<T>.reportLeak()",
            "previous_method_pd": "private void io.netty.util.ResourceLeakDetector.reportLeak()",
            "previous_file": "common/src/main/java/io/netty/util/ResourceLeakDetector.java",
            "previous_commit": "2b811c7895e8c11d64b25fa6c1308846392e2be0",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.959023539668701,
                "p_value": 0.0,
                "effect_size": 0.10373018711321312,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 248863,
                    "after": 244620
                }
            }
        }
    ],
    "deea51e6093db224878b33eaefc3321f2a0d4a07": [
        {
            "commit_message": "Disable Huffman encoding for small headers (#9260)\n\nMotivation:\r\n\r\nHuffman coding saves only a little space, but has a huge CPU cost\r\n\r\nModification:\r\n\r\nDisable huff coding for headers smaller than 512 bytes.  Also, add a\r\nconfigurable limit to the encoder.\r\n\r\nResult:\r\n\r\nFaster HPACK\r\n\r\nBEFORE:\r\n```\r\nBenchmark                     (duplicates)  (limitToAscii)  (sensitive)  (size)  Mode  Cnt       Score       Error  Units\r\nHpackEncoderBenchmark.encode          true            true         true   SMALL  avgt   10    2572.595 \u00b1    16.184  ns/op\r\nHpackEncoderBenchmark.encode          true            true         true  MEDIUM  avgt   10   19580.815 \u00b1   397.780  ns/op\r\nHpackEncoderBenchmark.encode          true            true         true   LARGE  avgt   10  379456.381 \u00b1  2059.919  ns/op\r\nHpackEncoderBenchmark.encode          true            true        false   SMALL  avgt   10     730.579 \u00b1     8.116  ns/op\r\nHpackEncoderBenchmark.encode          true            true        false  MEDIUM  avgt   10    2087.590 \u00b1    84.644  ns/op\r\nHpackEncoderBenchmark.encode          true            true        false   LARGE  avgt   10   11725.228 \u00b1    89.298  ns/op\r\nHpackEncoderBenchmark.encode          true           false         true   SMALL  avgt   10     555.971 \u00b1     5.120  ns/op\r\nHpackEncoderBenchmark.encode          true           false         true  MEDIUM  avgt   10    2831.874 \u00b1    41.801  ns/op\r\nHpackEncoderBenchmark.encode          true           false         true   LARGE  avgt   10   36054.025 \u00b1   179.504  ns/op\r\nHpackEncoderBenchmark.encode          true           false        false   SMALL  avgt   10     340.337 \u00b1     3.313  ns/op\r\nHpackEncoderBenchmark.encode          true           false        false  MEDIUM  avgt   10    1006.817 \u00b1     8.942  ns/op\r\nHpackEncoderBenchmark.encode          true           false        false   LARGE  avgt   10    8784.168 \u00b1   164.014  ns/op\r\nHpackEncoderBenchmark.encode         false            true         true   SMALL  avgt   10    2561.934 \u00b1    27.056  ns/op\r\nHpackEncoderBenchmark.encode         false            true         true  MEDIUM  avgt   10   22061.105 \u00b1   154.533  ns/op\r\nHpackEncoderBenchmark.encode         false            true         true   LARGE  avgt   10  435744.897 \u00b1  8853.388  ns/op\r\nHpackEncoderBenchmark.encode         false            true        false   SMALL  avgt   10    2737.683 \u00b1    47.142  ns/op\r\nHpackEncoderBenchmark.encode         false            true        false  MEDIUM  avgt   10   22385.146 \u00b1    98.430  ns/op\r\nHpackEncoderBenchmark.encode         false            true        false   LARGE  avgt   10  408159.698 \u00b1 12044.931  ns/op\r\nHpackEncoderBenchmark.encode         false           false         true   SMALL  avgt   10     544.213 \u00b1     3.279  ns/op\r\nHpackEncoderBenchmark.encode         false           false         true  MEDIUM  avgt   10    2908.978 \u00b1    31.026  ns/op\r\nHpackEncoderBenchmark.encode         false           false         true   LARGE  avgt   10   36471.262 \u00b1  1044.010  ns/op\r\nHpackEncoderBenchmark.encode         false           false        false   SMALL  avgt   10     609.305 \u00b1     4.371  ns/op\r\nHpackEncoderBenchmark.encode         false           false        false  MEDIUM  avgt   10    3223.946 \u00b1    23.505  ns/op\r\nHpackEncoderBenchmark.encode         false           false        false   LARGE  avgt   10   39975.152 \u00b1   655.196  ns/op\r\n```\r\n\r\nAFTER:\r\n```\r\nNEW AFTER\r\n\r\nBenchmark                     (duplicates)  (limitToAscii)  (sensitive)  (size)  Mode  Cnt     Score     Error  Units\r\nHpackEncoderBenchmark.encode          true            true         true   SMALL  avgt    5   379.473 \u00b1 133.815  ns/op\r\nHpackEncoderBenchmark.encode          true            true         true  MEDIUM  avgt    5  1118.772 \u00b1  89.258  ns/op\r\nHpackEncoderBenchmark.encode          true            true         true   LARGE  avgt    5  5366.828 \u00b1  89.746  ns/op\r\nHpackEncoderBenchmark.encode          true            true        false   SMALL  avgt    5   284.401 \u00b1   2.088  ns/op\r\nHpackEncoderBenchmark.encode          true            true        false  MEDIUM  avgt    5   922.805 \u00b1  10.796  ns/op\r\nHpackEncoderBenchmark.encode          true            true        false   LARGE  avgt    5  8727.831 \u00b1 462.138  ns/op\r\nHpackEncoderBenchmark.encode          true           false         true   SMALL  avgt    5   337.093 \u00b1  22.585  ns/op\r\nHpackEncoderBenchmark.encode          true           false         true  MEDIUM  avgt    5   693.689 \u00b1  16.351  ns/op\r\nHpackEncoderBenchmark.encode          true           false         true   LARGE  avgt    5  5616.786 \u00b1  98.647  ns/op\r\nHpackEncoderBenchmark.encode          true           false        false   SMALL  avgt    5   286.708 \u00b1  13.765  ns/op\r\nHpackEncoderBenchmark.encode          true           false        false  MEDIUM  avgt    5   906.279 \u00b1  32.338  ns/op\r\nHpackEncoderBenchmark.encode          true           false        false   LARGE  avgt    5  8304.736 \u00b1 128.584  ns/op\r\nHpackEncoderBenchmark.encode         false            true         true   SMALL  avgt    5   351.381 \u00b1  15.547  ns/op\r\nHpackEncoderBenchmark.encode         false            true         true  MEDIUM  avgt    5  1188.166 \u00b1   7.023  ns/op\r\nHpackEncoderBenchmark.encode         false            true         true   LARGE  avgt    5  6876.009 \u00b1  48.117  ns/op\r\nHpackEncoderBenchmark.encode         false            true        false   SMALL  avgt    5   434.759 \u00b1   8.619  ns/op\r\nHpackEncoderBenchmark.encode         false            true        false  MEDIUM  avgt    5   954.588 \u00b1  58.514  ns/op\r\nHpackEncoderBenchmark.encode         false            true        false   LARGE  avgt    5  8534.017 \u00b1 552.597  ns/op\r\nHpackEncoderBenchmark.encode         false           false         true   SMALL  avgt    5   223.713 \u00b1   4.823  ns/op\r\nHpackEncoderBenchmark.encode         false           false         true  MEDIUM  avgt    5  1181.538 \u00b1  11.851  ns/op\r\nHpackEncoderBenchmark.encode         false           false         true   LARGE  avgt    5  6670.830 \u00b1 267.927  ns/op\r\nHpackEncoderBenchmark.encode         false           false        false   SMALL  avgt    5   424.609 \u00b1  27.477  ns/op\r\nHpackEncoderBenchmark.encode         false           false        false  MEDIUM  avgt    5  1003.578 \u00b1  53.991  ns/op\r\nHpackEncoderBenchmark.encode         false           false        false   LARGE  avgt    5  8428.932 \u00b1 102.838  ns/op\r\n```",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private void io.netty.handler.codec.http2.HpackEncoder.encodeStringLiteral(io.netty.buffer.ByteBuf,java.lang.CharSequence)",
            "method_name_cc": "private void io.netty.handler.codec.http2.HpackEncoder.encodeStringLiteral(ByteBuf out, CharSequence string)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_method_cc": "private void io.netty.handler.codec.http2.HpackEncoder.encodeStringLiteral(ByteBuf out, CharSequence string)",
            "previous_method_pd": "private void io.netty.handler.codec.http2.HpackEncoder.encodeStringLiteral(io.netty.buffer.ByteBuf,java.lang.CharSequence)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackEncoder.java",
            "previous_commit": "131be58f4866e30626d53386df0c236d17044891",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -9.623046555205852,
                "p_value": 1.138006587290518e-29,
                "effect_size": 0.17517989911305554,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 2701,
                    "after": 2865
                }
            }
        }
    ],
    "2b7de5a50bb3feb1a351dcd1ce1da9474ae256ae": [
        {
            "commit_message": "Magazines must be freed under the expand lock (#14336)\n\nMotivation:\r\nIt's unlikely, but possible, for our freeing of magazines to run\r\nconcurrently with magazine expansion. If that happens, we might not free\r\nall magazines.\r\n\r\nModification:\r\nFree the magazines under the expansion lock, and short-circuit the\r\nmagazine expansion if the allocator has been freed.\r\n\r\nResult:\r\nFixes a data race that could leave magazines and their chunks un-freed.",
            "benchmark": "io.netty.microbench.buffer.ByteBufAllocatorConcurrentBenchmark.allocateReleaseAdaptive",
            "method_name_pd": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int)",
            "method_name_cc": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int currentLength)",
            "file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_method_cc": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int currentLength)",
            "previous_method_pd": "private boolean io.netty.buffer.AdaptivePoolingAllocator.tryExpandMagazines(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AdaptivePoolingAllocator.java",
            "previous_commit": "afb475dabd5ca9eaa94ccf07f0ecd8431db008ba",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "improvement",
                "median_change_percentage": -5.0349469916753105,
                "p_value": 0.026303972204145917,
                "effect_size": 0.29914529914529914,
                "effect_size_interpretation": "small",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 39,
                    "after": 36
                }
            }
        }
    ],
    "a60825c3b425892af9be3e9284677aa8a58faa6b": [
        {
            "commit_message": "Dont create stack variable in adjustMarkers. (#11033)\n\nMotivation:\r\n\r\nNo extra variable is needed.\r\n\r\nModification:\r\n\r\nRemove extra variable\r\n\r\nResult:\r\n\r\nFixes #11032",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "protected final void io.netty.buffer.AbstractByteBuf.adjustMarkers(int)",
            "method_name_cc": "protected final void io.netty.buffer.AbstractByteBuf.adjustMarkers(int decrement)",
            "file": "buffer/src/main/java/io/netty/buffer/AbstractByteBuf.java",
            "previous_method_cc": "protected final void io.netty.buffer.AbstractByteBuf.adjustMarkers(int decrement)",
            "previous_method_pd": "protected final void io.netty.buffer.AbstractByteBuf.adjustMarkers(int)",
            "previous_file": "buffer/src/main/java/io/netty/buffer/AbstractByteBuf.java",
            "previous_commit": "5158e3976dcdcb0ed878763ca0fa2014c8f949d4",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": -0.1080080234531708,
                "p_value": 1.602703725617846e-28,
                "effect_size": 0.007634704769805485,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1399389,
                    "after": 1407902
                }
            }
        }
    ],
    "3a41a97b0e00145ec20c699b8ec472cb42965756": [
        {
            "commit_message": "Support large or variable chunk sizes (#11469)\n\n\r\nMotivation:\r\n\r\nChunks are splitted up into even smaller chunks when the underlying\r\nbuffer's readable bytes are less than the chunk size.\r\n\r\nThe underlying buffer can be smaller than a chunk size if:\r\n\r\n- The chunk size is larger than the maximum plaintext chunk allowed by the TLS RFC,\r\n  see: io.netty.handler.ssl.SslHandler.MAX_PLAINTEXT_LENGTH.\r\n\r\n- The chunk sizes are variable in size,\r\n  which may cause Netty guess a buffer size that is smaller than a chunk size.\r\n\r\nModification:\r\n\r\nCreate a variable in HttpObjectDecoder: ByteBuf chunkedContent\r\n\r\n- Initialize chunkedContent in READ_CHUNK_SIZE with chunkSize as buffer size.\r\n\r\n- In READ_CHUNKED_CONTENT write bytes into chunkedContent\r\n\r\n  - If the remaining chunk size is not 0 and toRead ==maxChunkSize,\r\n    create a chunk using the chunkedContent and add it to the output messages\r\n    before re-initializing chunkedContent with the remaining chunkSize as buffer size.\r\n\r\n  - If the remaining chunk size is not 0 and toRead != maxChunkSize,\r\n    return without adding any output messages.\r\n\r\n  - If the remaining chunk size is 0,\r\n    create a chunk using the chunkedContent and add it to the output messages;\r\n    set chunkedContent = null and fall-through.\r\n\r\nResult:\r\n\r\nSupport chunk sizes higher than the underlying buffer's readable bytes.\r\n\r\nCo-authored-by: Nitesh Kant <nitesh_kant@apple.com>\r\nCo-authored-by: Norman Maurer <norman_maurer@apple.com>",
            "benchmark": "io.netty.microbench.http.HttpRequestDecoderBenchmark.testDecodeWholeRequestInMultipleStepsMixedDelimiters",
            "method_name_pd": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List) throws java.lang.Exception",
            "method_name_cc": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(ChannelHandlerContext ctx, ByteBuf buffer, List<Object> out)",
            "file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_method_cc": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(ChannelHandlerContext ctx, ByteBuf buffer, List<Object> out)",
            "previous_method_pd": "protected void io.netty.handler.codec.http.HttpObjectDecoder.decode(io.netty.channel.ChannelHandlerContext,io.netty.buffer.ByteBuf,java.util.List) throws java.lang.Exception",
            "previous_file": "codec-http/src/main/java/io/netty/handler/codec/http/HttpObjectDecoder.java",
            "previous_commit": "1ce76e7e9988c82aba7e6c6c90ad54c084315b6c",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 0.22564874012786762,
                "p_value": 0.0,
                "effect_size": -0.050642524633681525,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 1349640,
                    "after": 1368102
                }
            }
        }
    ],
    "570c5d75bd172fbb2f6f68685326d4acb3978482": [
        {
            "commit_message": "Avoid failing HTTP/2 requests with `upgrade-insecure-requests` (#12799)\n\nMotivation:\r\nThis is a non-standard header that is not _explicitly_ called out as connection related, even though it can be argued that it is.\r\nRegardless, Chrome and Firefox do actually send this header in their HTTP/2 requests, so rejecting these is quite troublesome.\r\nSafari doesn't send this header.\r\n\r\nModification:\r\nRemove the check for `upgrade-insecure-requests` in the header validation in HpackDecoder.\r\nAlso update tests to match.\r\n\r\nResult:\r\nHTTP/2 requests from Chrome and Firefox are no longer rejected by the header validation.\r\n\r\nFixes #12798",
            "benchmark": "io.netty.handler.codec.http2.HpackDecoderBenchmark.decode",
            "method_name_pd": "private static boolean io.netty.handler.codec.http2.HpackDecoder.isConnectionHeader(java.lang.CharSequence)",
            "method_name_cc": "private static boolean io.netty.handler.codec.http2.HpackDecoder.isConnectionHeader(CharSequence name)",
            "file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackDecoder.java",
            "previous_method_cc": "private static boolean io.netty.handler.codec.http2.HpackDecoder.isConnectionHeader(CharSequence name)",
            "previous_method_pd": "private static boolean io.netty.handler.codec.http2.HpackDecoder.isConnectionHeader(java.lang.CharSequence)",
            "previous_file": "codec-http2/src/main/java/io/netty/handler/codec/http2/HpackDecoder.java",
            "previous_commit": "75982ea652eee022287c0af29ed629be4d0a1bfd",
            "performance_diff": -0.0,
            "significance": {
                "change_type": "unchanged",
                "median_change_percentage": 5.642994241842611,
                "p_value": 0.0,
                "effect_size": -0.038406440160649626,
                "effect_size_interpretation": "negligible",
                "statistically_significant": 1,
                "sample_size": {
                    "before": 3296782,
                    "after": 3271649
                }
            }
        }
    ]
}